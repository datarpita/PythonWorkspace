{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a piece of code that breaks a given sentence into words and store them in a list. Then print the list as well as the length of the list. Use the NLTK tokeniser to tokenise words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import ast, sys\n",
    "sentence = 'I love pasta'\n",
    "\n",
    "# tokenise sentence into words\n",
    "words = word_tokenize(sentence)# write your code here\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a piece of code that breaks a given sentence into words and stores them in a list. Then remove the stop words from this list and then print the list as well as the length of the list. Again, use the NLTK tokeniser to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import ast, sys\n",
    "sentence = 'Education is the most powerful weapon that you can use to change the world'\n",
    "\n",
    "# change sentence to lowercase\n",
    "sentence = sentence.lower()# write code here\n",
    "\n",
    "# tokenise sentence into words\n",
    "words = word_tokenize(sentence)# write code here\n",
    "\n",
    "# extract nltk stop word list\n",
    "stopwords = stopwords.words(\"english\")# write code here\n",
    "\n",
    "# remove stop words\n",
    "no_stops = [w for w in words if w not in stopwords]# write code here\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(no_stops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python code using the NLTK library that breaks a given piece of text containing multiple sentences into different sentences. Finally print the total number of sentences in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import ast, sys\n",
    "text = 'Develop a passion for your learning. If you do, you\\'ll never cease to grow.'\n",
    "\n",
    "# change sentence to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# tokenise sentence into words\n",
    "sentences = sent_tokenize(text)# write code here\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NLTK’s regex tokeniser to extract all the mentions from a given tweet and then print the total number of mentions. A mention comprises of a ‘@’ symbol followed by a username containing either alphabets, numbers or underscores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import ast, sys\n",
    "text = 'So excited to be a part of machine learning and artificial intelligence program made by @upgrad and @iiitb'\n",
    "\n",
    "# change text to lowercase\n",
    "text = text.lower()# write code here\n",
    "\n",
    "# pattern to extract mentions\n",
    "pattern = '@[\\w]+'# write regex pattern here\n",
    "\n",
    "# extract mentions by using regex tokeniser\n",
    "mentions = regexp_tokenize(text, pattern)# write code here\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(mentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first 100 rows of the spam messages data to create a bag-of-words model after changing the text to lower case, tokenising and removing stop words (you can use the preprocess function that you saw professor Srinath use in the bag-of-words demonstration video). Print the shape of the bag-of-words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all necessary libraries\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                               message  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv(\"SMSSpamCollection.txt\", sep = \"\\t\", names=[\"label\", \"message\"])\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam100 = spam.iloc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = spam100['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()\n",
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go until jurong point, crazy.. available only in bugis n great world la e buffet... cine there got amore wat...',\n",
       " 'ok lar... joking wif u oni...',\n",
       " \"free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005. text fa to 87121 to receive entry question(std txt rate)t&c's apply 08452810075over18's\",\n",
       " 'u dun say so early hor... u c already then say...',\n",
       " \"nah i don't think he goes to usf, he lives around here though\",\n",
       " \"freemsg hey there darling it's been 3 week's now and no word back! i'd like some fun you up for it still? tb ok! xxx std chgs to send, £1.50 to rcv\",\n",
       " 'even my brother is not like to speak with me. they treat me like aids patent.',\n",
       " \"as per your request 'melle melle (oru minnaminunginte nurungu vettam)' has been set as your callertune for all callers. press *9 to copy your friends callertune\",\n",
       " 'winner!! as a valued network customer you have been selected to receivea £900 prize reward! to claim call 09061701461. claim code kl341. valid 12 hours only.',\n",
       " 'had your mobile 11 months or more? u r entitled to update to the latest colour mobiles with camera for free! call the mobile update co free on 08002986030',\n",
       " \"i'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? i've cried enough today.\",\n",
       " 'six chances to win cash! from 100 to 20,000 pounds txt> csh11 and send to 87575. cost 150p/day, 6days, 16+ tsandcs apply reply hl 4 info',\n",
       " 'urgent! you have won a 1 week free membership in our £100,000 prize jackpot! txt the word: claim to no: 81010 t&c www.dbuk.net lccltd pobox 4403ldnw1a7rw18',\n",
       " \"i've been searching for the right words to thank you for this breather. i promise i wont take your help for granted and will fulfil my promise. you have been wonderful and a blessing at all times.\",\n",
       " 'i have a date on sunday with will!!',\n",
       " 'xxxmobilemovieclub: to use your credit, click the wap link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=qjkgighjjgcbl',\n",
       " \"oh k...i'm watching here:)\",\n",
       " 'eh u remember how 2 spell his name... yes i did. he v naughty make until i v wet.',\n",
       " 'fine if that\\x92s the way u feel. that\\x92s the way its gota b',\n",
       " 'england v macedonia - dont miss the goals/team news. txt ur national team to 87077 eg england to 87077 try:wales, scotland 4txt/ú1.20 poboxox36504w45wq 16+',\n",
       " 'is that seriously how you spell his name?',\n",
       " 'i‘m going to try for 2 months ha ha only joking',\n",
       " 'so ü pay first lar... then when is da stock comin...',\n",
       " 'aft i finish my lunch then i go str down lor. ard 3 smth lor. u finish ur lunch already?',\n",
       " 'ffffffffff. alright no way i can meet up with you sooner?',\n",
       " \"just forced myself to eat a slice. i'm really not hungry tho. this sucks. mark is getting worried. he knows i'm sick when i turn down pizza. lol\",\n",
       " 'lol your always so convincing.',\n",
       " \"did you catch the bus ? are you frying an egg ? did you make a tea? are you eating your mom's left over dinner ? do you feel my love ?\",\n",
       " \"i'm back &amp; we're packing the car now, i'll let you know if there's room\",\n",
       " 'ahhh. work. i vaguely remember that! what does it feel like? lol',\n",
       " \"wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us\",\n",
       " \"yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. till 2! but we won't go there! not doing too badly cheers. you? \",\n",
       " 'k tell me anything about you.',\n",
       " 'for fear of fainting with the of all that housework you just did? quick have a cuppa',\n",
       " 'thanks for your subscription to ringtone uk your mobile will be charged £5/month please confirm by replying yes or no. if you reply no you will not be charged',\n",
       " 'yup... ok i go home look at the timings then i msg ü again... xuhui going to learn on 2nd may too but her lesson is at 8am',\n",
       " \"oops, i'll let you know when my roommate's done\",\n",
       " 'i see the letter b on my car',\n",
       " 'anything lor... u decide...',\n",
       " \"hello! how's you and how did saturday go? i was just texting to see if you'd decided to do anything tomo. not that i'm trying to invite myself or anything!\",\n",
       " 'pls go ahead with watts. i just wanted to be sure. do have a great weekend. abiola',\n",
       " 'did i forget to tell you ? i want you , i need you, i crave you ... but most of all ... i love you my sweet arabian steed ... mmmmmm ... yummy',\n",
       " '07732584351 - rodger burns - msg = we tried to call you re your reply to our sms for a free nokia mobile + free camcorder. please call now 08000930705 for delivery tomorrow',\n",
       " 'who are you seeing?',\n",
       " 'great! i hope you like your man well endowed. i am  &lt;#&gt;  inches...',\n",
       " 'no calls..messages..missed calls',\n",
       " \"didn't you get hep b immunisation in nigeria.\",\n",
       " 'fair enough, anything going on?',\n",
       " \"yeah hopefully, if tyler can't do it i could maybe ask around a bit\",\n",
       " \"u don't know how stubborn i am. i didn't even want to go to the hospital. i kept telling mark i'm not a weak sucker. hospitals are for weak suckers.\",\n",
       " 'what you thinked about me. first time you saw me in class.',\n",
       " 'a gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole second gram for  &lt;#&gt;',\n",
       " \"k fyi x has a ride early tomorrow morning but he's crashing at our place tonight\",\n",
       " 'wow. i never realized that you were so embarassed by your accomodations. i thought you liked it, since i was doing the best i could and you always seemed so happy about \"the cave\". i\\'m sorry i didn\\'t and don\\'t have more to give. i\\'m sorry i offered. i\\'m sorry your room was so embarassing.',\n",
       " 'sms. ac sptv: the new jersey devils and the detroit red wings play ice hockey. correct or incorrect? end? reply end sptv',\n",
       " 'do you know what mallika sherawat did yesterday? find out now @  &lt;url&gt;',\n",
       " 'congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! c suprman v, matrix3, starwars3, etc all 4 free! bx420-ip4-5we. 150pm. dont miss out! ',\n",
       " \"sorry, i'll call later in meeting.\",\n",
       " 'tell where you reached',\n",
       " 'yes..gauti and sehwag out of odi series.',\n",
       " \"your gonna have to pick up a $1 burger for yourself on your way home. i can't even move. pain is killing me.\",\n",
       " 'ha ha ha good joke. girls are situation seekers.',\n",
       " 'its a part of checking iq',\n",
       " 'sorry my roommates took forever, it ok if i come by now?',\n",
       " 'ok lar i double check wif da hair dresser already he said wun cut v short. he said will cut until i look nice.',\n",
       " 'as a valued customer, i am pleased to advise you that following recent review of your mob no. you are awarded with a £1500 bonus prize, call 09066364589',\n",
       " 'today is \"song dedicated day..\" which song will u dedicate for me? send this to all ur valuable frnds but first rply me...',\n",
       " 'urgent ur awarded a complimentary trip to eurodisinc trav, aco&entry41 or £1000. to claim txt dis to 87121 18+6*£1.50(morefrmmob. shracomorsglsuplt)10, ls1 3aj',\n",
       " 'did you hear about the new \"divorce barbie\"? it comes with all of ken\\'s stuff!',\n",
       " 'i plane to give on this month end.',\n",
       " 'wah lucky man... then can save money... hee...',\n",
       " 'finished class where are you.',\n",
       " 'hi babe im at home now wanna do something? xx',\n",
       " 'k..k:)where are you?how did you performed?',\n",
       " 'u can call me now...',\n",
       " 'i am waiting machan. call me once you free.',\n",
       " 'thats cool. i am a gentleman and will treat you with dignity and respect.',\n",
       " 'i like you peoples very much:) but am very shy pa.',\n",
       " 'does not operate after  &lt;#&gt;  or what',\n",
       " \"its not the same here. still looking for a job. how much do ta's earn there.\",\n",
       " \"sorry, i'll call later\",\n",
       " 'k. did you call me just now ah? ',\n",
       " 'ok i am on the way to home hi hi',\n",
       " 'you will be in the place of that man',\n",
       " 'yup next stop.',\n",
       " \"i call you later, don't have network. if urgnt, sms me.\",\n",
       " \"for real when u getting on yo? i only need 2 more tickets and one more jacket and i'm done. i already used all my multis.\",\n",
       " \"yes i started to send requests to make it but pain came back so i'm back in bed. double coins at the factory too. i gotta cash in all my nitros.\",\n",
       " \"i'm really not up to it still tonight babe\",\n",
       " 'ela kano.,il download, come wen ur free..',\n",
       " 'yeah do! don‘t stand to close tho- you‘ll catch something!',\n",
       " \"sorry to be a pain. is it ok if we meet another night? i spent late afternoon in casualty and that means i haven't done any of y stuff42moro and that includes all my time sheets and that. sorry. \",\n",
       " 'smile in pleasure smile in pain smile when trouble pours like rain smile when sum1 hurts u smile becoz someone still loves to see u smiling!!',\n",
       " 'please call our customer service representative on 0800 169 6031 between 10am-9pm as you have won a guaranteed £1000 cash or £5000 prize!',\n",
       " 'havent planning to buy later. i check already lido only got 530 show in e afternoon. u finish work already?',\n",
       " 'your free ringtone is waiting to be collected. simply text the password \"mix\" to 85069 to verify. get usher and britney. fml, po box 5249, mk17 92h. 450ppw 16',\n",
       " 'watching telugu movie..wat abt u?',\n",
       " 'i see. when we finish we have loads of loans to pay',\n",
       " 'hi. wk been ok - on hols now! yes on for a bit of a run. forgot that i have hairdressers appointment at four so need to get home n shower beforehand. does that cause prob for u?\"',\n",
       " 'i see a cup of coffee animation']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list = documents.tolist()\n",
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "new_doc_list = []\n",
    "for doc in doc_list:\n",
    "    words = word_tokenize(doc)\n",
    "    uniq_words = [w for w in words if w not in stopwords.words('english')]\n",
    "    doc = \" \".join(uniq_words)\n",
    "    new_doc_list.append(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point , crazy.. available bugis n great world la e buffet ... cine got amore wat ...',\n",
       " 'ok lar ... joking wif u oni ...',\n",
       " \"free entry 2 wkly comp win fa cup final tkts 21st may 2005. text fa 87121 receive entry question ( std txt rate ) & c 's apply 08452810075over18 's\",\n",
       " 'u dun say early hor ... u c already say ...',\n",
       " \"nah n't think goes usf , lives around though\",\n",
       " \"freemsg hey darling 's 3 week 's word back ! 'd like fun still ? tb ok ! xxx std chgs send , £1.50 rcv\",\n",
       " 'even brother like speak . treat like aids patent .',\n",
       " \"per request 'melle melle ( oru minnaminunginte nurungu vettam ) ' set callertune callers . press *9 copy friends callertune\",\n",
       " 'winner ! ! valued network customer selected receivea £900 prize reward ! claim call 09061701461. claim code kl341 . valid 12 hours .',\n",
       " 'mobile 11 months ? u r entitled update latest colour mobiles camera free ! call mobile update co free 08002986030',\n",
       " \"'m gon na home soon n't want talk stuff anymore tonight , k ? 've cried enough today .\",\n",
       " 'six chances win cash ! 100 20,000 pounds txt > csh11 send 87575. cost 150p/day , 6days , 16+ tsandcs apply reply hl 4 info',\n",
       " 'urgent ! 1 week free membership £100,000 prize jackpot ! txt word : claim : 81010 & c www.dbuk.net lccltd pobox 4403ldnw1a7rw18',\n",
       " \"'ve searching right words thank breather . promise wont take help granted fulfil promise . wonderful blessing times .\",\n",
       " 'date sunday ! !',\n",
       " 'xxxmobilemovieclub : use credit , click wap link next txt message click > > http : //wap . xxxmobilemovieclub.com ? n=qjkgighjjgcbl',\n",
       " \"oh k ... 'm watching : )\",\n",
       " 'eh u remember 2 spell name ... yes . v naughty make v wet .',\n",
       " 'fine that\\x92s way u feel . that\\x92s way gota b',\n",
       " 'england v macedonia - dont miss goals/team news . txt ur national team 87077 eg england 87077 try : wales , scotland 4txt/ú1.20 poboxox36504w45wq 16+',\n",
       " 'seriously spell name ?',\n",
       " '‘ going try 2 months ha ha joking',\n",
       " 'ü pay first lar ... da stock comin ...',\n",
       " 'aft finish lunch go str lor . ard 3 smth lor . u finish ur lunch already ?',\n",
       " 'ffffffffff . alright way meet sooner ?',\n",
       " \"forced eat slice . 'm really hungry tho . sucks . mark getting worried . knows 'm sick turn pizza . lol\",\n",
       " 'lol always convincing .',\n",
       " \"catch bus ? frying egg ? make tea ? eating mom 's left dinner ? feel love ?\",\n",
       " \"'m back & amp ; 're packing car , 'll let know 's room\",\n",
       " 'ahhh . work . vaguely remember ! feel like ? lol',\n",
       " \"wait 's still clear , sure sarcastic 's x n't want live us\",\n",
       " \"yeah got 2 v apologetic . n fallen actin like spoilt child got caught . till 2 ! wo n't go ! badly cheers . ?\",\n",
       " 'k tell anything .',\n",
       " 'fear fainting housework ? quick cuppa',\n",
       " 'thanks subscription ringtone uk mobile charged £5/month please confirm replying yes . reply charged',\n",
       " 'yup ... ok go home look timings msg ü ... xuhui going learn 2nd may lesson 8am',\n",
       " \"oops , 'll let know roommate 's done\",\n",
       " 'see letter b car',\n",
       " 'anything lor ... u decide ...',\n",
       " \"hello ! 's saturday go ? texting see 'd decided anything tomo . 'm trying invite anything !\",\n",
       " 'pls go ahead watts . wanted sure . great weekend . abiola',\n",
       " 'forget tell ? want , need , crave ... ... love sweet arabian steed ... mmmmmm ... yummy',\n",
       " '07732584351 - rodger burns - msg = tried call reply sms free nokia mobile + free camcorder . please call 08000930705 delivery tomorrow',\n",
       " 'seeing ?',\n",
       " 'great ! hope like man well endowed . & lt ; # & gt ; inches ...',\n",
       " 'calls..messages..missed calls',\n",
       " \"n't get hep b immunisation nigeria .\",\n",
       " 'fair enough , anything going ?',\n",
       " \"yeah hopefully , tyler ca n't could maybe ask around bit\",\n",
       " \"u n't know stubborn . n't even want go hospital . kept telling mark 'm weak sucker . hospitals weak suckers .\",\n",
       " 'thinked . first time saw class .',\n",
       " 'gram usually runs like & lt ; # & gt ; , half eighth smarter though gets almost whole second gram & lt ; # & gt ;',\n",
       " \"k fyi x ride early tomorrow morning 's crashing place tonight\",\n",
       " \"wow . never realized embarassed accomodations . thought liked , since best could always seemed happy `` cave '' . 'm sorry n't n't give . 'm sorry offered . 'm sorry room embarassing .\",\n",
       " 'sms . ac sptv : new jersey devils detroit red wings play ice hockey . correct incorrect ? end ? reply end sptv',\n",
       " 'know mallika sherawat yesterday ? find @ & lt ; url & gt ;',\n",
       " 'congrats ! 1 year special cinema pass 2 . call 09061209465 ! c suprman v , matrix3 , starwars3 , etc 4 free ! bx420-ip4-5we . 150pm . dont miss !',\n",
       " \"sorry , 'll call later meeting .\",\n",
       " 'tell reached',\n",
       " 'yes..gauti sehwag odi series .',\n",
       " \"gon na pick $ 1 burger way home . ca n't even move . pain killing .\",\n",
       " 'ha ha ha good joke . girls situation seekers .',\n",
       " 'part checking iq',\n",
       " 'sorry roommates took forever , ok come ?',\n",
       " 'ok lar double check wif da hair dresser already said wun cut v short . said cut look nice .',\n",
       " 'valued customer , pleased advise following recent review mob . awarded £1500 bonus prize , call 09066364589',\n",
       " \"today `` song dedicated day.. '' song u dedicate ? send ur valuable frnds first rply ...\",\n",
       " 'urgent ur awarded complimentary trip eurodisinc trav , aco & entry41 £1000 . claim txt dis 87121 18+6*£1.50 ( morefrmmob . shracomorsglsuplt ) 10 , ls1 3aj',\n",
       " \"hear new `` divorce barbie '' ? comes ken 's stuff !\",\n",
       " 'plane give month end .',\n",
       " 'wah lucky man ... save money ... hee ...',\n",
       " 'finished class .',\n",
       " 'hi babe im home wan na something ? xx',\n",
       " 'k..k : ) ? performed ?',\n",
       " 'u call ...',\n",
       " 'waiting machan . call free .',\n",
       " 'thats cool . gentleman treat dignity respect .',\n",
       " 'like peoples much : ) shy pa .',\n",
       " 'operate & lt ; # & gt ;',\n",
       " \". still looking job . much ta 's earn .\",\n",
       " \"sorry , 'll call later\",\n",
       " 'k. call ah ?',\n",
       " 'ok way home hi hi',\n",
       " 'place man',\n",
       " 'yup next stop .',\n",
       " \"call later , n't network . urgnt , sms .\",\n",
       " \"real u getting yo ? need 2 tickets one jacket 'm done . already used multis .\",\n",
       " \"yes started send requests make pain came back 'm back bed . double coins factory . got ta cash nitros .\",\n",
       " \"'m really still tonight babe\",\n",
       " 'ela kano. , il download , come wen ur free..',\n",
       " 'yeah ! ‘ stand close tho- ‘ catch something !',\n",
       " \"sorry pain . ok meet another night ? spent late afternoon casualty means n't done stuff42moro includes time sheets . sorry .\",\n",
       " 'smile pleasure smile pain smile trouble pours like rain smile sum1 hurts u smile becoz someone still loves see u smiling ! !',\n",
       " 'please call customer service representative 0800 169 6031 10am-9pm guaranteed £1000 cash £5000 prize !',\n",
       " 'havent planning buy later . check already lido got 530 show e afternoon . u finish work already ?',\n",
       " \"free ringtone waiting collected . simply text password `` mix '' 85069 verify . get usher britney . fml , po box 5249 , mk17 92h . 450ppw 16\",\n",
       " 'watching telugu movie..wat abt u ?',\n",
       " 'see . finish loads loans pay',\n",
       " \"hi . wk ok - hols ! yes bit run . forgot hairdressers appointment four need get home n shower beforehand . cause prob u ? ''\",\n",
       " 'see cup coffee animation']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words model\n",
    "vectorizer = CountVectorizer()\n",
    "bow_model = vectorizer.fit_transform(new_doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the dataframe\n",
    "bow_model_df = pd.DataFrame(bow_model.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '07732584351', '0800', '08000930705', '08002986030', '08452810075over18', '09061209465', '09061701461', '09066364589', '10', '100', '1000', '10am', '11', '12', '1500', '150p', '150pm', '16', '169', '18', '20', '2005', '21st', '2nd', '3aj', '4403ldnw1a7rw18', '450ppw', '4txt', '50', '5000', '5249', '530', '5we', '6031', '6days', '81010', '85069', '87077', '87121', '87575', '8am', '900', '92h', '9pm', 'abiola', 'abt', 'ac', 'accomodations', 'aco', 'actin', 'advise', 'aft', 'afternoon', 'ah', 'ahead', 'ahhh', 'aids', 'almost', 'already', 'alright', 'always', 'amore', 'amp', 'animation', 'another', 'anymore', 'anything', 'apologetic', 'apply', 'appointment', 'arabian', 'ard', 'around', 'ask', 'available', 'awarded', 'babe', 'back', 'badly', 'barbie', 'becoz', 'bed', 'beforehand', 'best', 'bit', 'blessing', 'bonus', 'box', 'breather', 'britney', 'brother', 'buffet', 'bugis', 'burger', 'burns', 'bus', 'buy', 'bx420', 'ca', 'call', 'callers', 'callertune', 'calls', 'camcorder', 'came', 'camera', 'car', 'cash', 'casualty', 'catch', 'caught', 'cause', 'cave', 'chances', 'charged', 'check', 'checking', 'cheers', 'chgs', 'child', 'cine', 'cinema', 'claim', 'class', 'clear', 'click', 'close', 'co', 'code', 'coffee', 'coins', 'collected', 'colour', 'com', 'come', 'comes', 'comin', 'comp', 'complimentary', 'confirm', 'congrats', 'convincing', 'cool', 'copy', 'correct', 'cost', 'could', 'crashing', 'crave', 'crazy', 'credit', 'cried', 'csh11', 'cup', 'cuppa', 'customer', 'cut', 'da', 'darling', 'date', 'day', 'dbuk', 'decide', 'decided', 'dedicate', 'dedicated', 'delivery', 'detroit', 'devils', 'dignity', 'dinner', 'dis', 'divorce', 'done', 'dont', 'double', 'download', 'dresser', 'dun', 'early', 'earn', 'eat', 'eating', 'eg', 'egg', 'eh', 'eighth', 'ela', 'embarassed', 'embarassing', 'end', 'endowed', 'england', 'enough', 'entitled', 'entry', 'entry41', 'etc', 'eurodisinc', 'even', 'fa', 'factory', 'fainting', 'fair', 'fallen', 'fear', 'feel', 'ffffffffff', 'final', 'find', 'fine', 'finish', 'finished', 'first', 'fml', 'following', 'forced', 'forever', 'forget', 'forgot', 'four', 'free', 'freemsg', 'friends', 'frnds', 'frying', 'fulfil', 'fun', 'fyi', 'gauti', 'gentleman', 'get', 'gets', 'getting', 'girls', 'give', 'go', 'goals', 'goes', 'going', 'gon', 'good', 'got', 'gota', 'gram', 'granted', 'great', 'gt', 'guaranteed', 'ha', 'hair', 'hairdressers', 'half', 'happy', 'havent', 'hear', 'hee', 'hello', 'help', 'hep', 'hey', 'hi', 'hl', 'hockey', 'hols', 'home', 'hope', 'hopefully', 'hor', 'hospital', 'hospitals', 'hours', 'housework', 'http', 'hungry', 'hurts', 'ice', 'il', 'im', 'immunisation', 'inches', 'includes', 'incorrect', 'info', 'invite', 'ip4', 'iq', 'jacket', 'jackpot', 'jersey', 'job', 'joke', 'joking', 'jurong', 'kano', 'ken', 'kept', 'killing', 'kl341', 'know', 'knows', 'la', 'lar', 'late', 'later', 'latest', 'lccltd', 'learn', 'left', 'lesson', 'let', 'letter', 'lido', 'like', 'liked', 'link', 'live', 'lives', 'll', 'loads', 'loans', 'lol', 'look', 'looking', 'lor', 'love', 'loves', 'ls1', 'lt', 'lucky', 'lunch', 'macedonia', 'machan', 'make', 'mallika', 'man', 'mark', 'matrix3', 'may', 'maybe', 'means', 'meet', 'meeting', 'melle', 'membership', 'message', 'messages', 'minnaminunginte', 'miss', 'missed', 'mix', 'mk17', 'mmmmmm', 'mob', 'mobile', 'mobiles', 'mom', 'money', 'month', 'months', 'morefrmmob', 'morning', 'move', 'movie', 'msg', 'much', 'multis', 'na', 'nah', 'name', 'national', 'naughty', 'need', 'net', 'network', 'never', 'new', 'news', 'next', 'nice', 'nigeria', 'night', 'nitros', 'nokia', 'nurungu', 'odi', 'offered', 'oh', 'ok', 'one', 'oni', 'oops', 'operate', 'oru', 'pa', 'packing', 'pain', 'part', 'pass', 'password', 'patent', 'pay', 'peoples', 'per', 'performed', 'pick', 'pizza', 'place', 'plane', 'planning', 'play', 'please', 'pleased', 'pleasure', 'pls', 'po', 'pobox', 'poboxox36504w45wq', 'point', 'pounds', 'pours', 'press', 'prize', 'prob', 'promise', 'qjkgighjjgcbl', 'question', 'quick', 'rain', 'rate', 'rcv', 're', 'reached', 'real', 'realized', 'really', 'receive', 'receivea', 'recent', 'red', 'remember', 'reply', 'replying', 'representative', 'request', 'requests', 'respect', 'review', 'reward', 'ride', 'right', 'ringtone', 'rodger', 'room', 'roommate', 'roommates', 'rply', 'run', 'runs', 'said', 'sarcastic', 'saturday', 'save', 'saw', 'say', 'scotland', 'searching', 'second', 'see', 'seeing', 'seekers', 'seemed', 'sehwag', 'selected', 'send', 'series', 'seriously', 'service', 'set', 'sheets', 'sherawat', 'short', 'show', 'shower', 'shracomorsglsuplt', 'shy', 'sick', 'simply', 'since', 'situation', 'six', 'slice', 'smarter', 'smile', 'smiling', 'sms', 'smth', 'someone', 'something', 'song', 'soon', 'sooner', 'sorry', 'speak', 'special', 'spell', 'spent', 'spoilt', 'sptv', 'stand', 'started', 'starwars3', 'std', 'steed', 'still', 'stock', 'stop', 'str', 'stubborn', 'stuff', 'stuff42moro', 'subscription', 'sucker', 'suckers', 'sucks', 'sum1', 'sunday', 'suprman', 'sure', 'sweet', 'ta', 'take', 'talk', 'tb', 'tea', 'team', 'tell', 'telling', 'telugu', 'text', 'texting', 'thank', 'thanks', 'that', 'thats', 'think', 'thinked', 'tho', 'though', 'thought', 'tickets', 'till', 'time', 'times', 'timings', 'tkts', 'today', 'tomo', 'tomorrow', 'tonight', 'took', 'trav', 'treat', 'tried', 'trip', 'trouble', 'try', 'trying', 'tsandcs', 'turn', 'txt', 'tyler', 'uk', 'update', 'ur', 'urgent', 'urgnt', 'url', 'us', 'use', 'used', 'usf', 'usher', 'usually', 'vaguely', 'valid', 'valuable', 'valued', 've', 'verify', 'vettam', 'wah', 'wait', 'waiting', 'wales', 'wan', 'want', 'wanted', 'wap', 'wat', 'watching', 'watts', 'way', 'weak', 'week', 'weekend', 'well', 'wen', 'wet', 'whole', 'wif', 'win', 'wings', 'winner', 'wk', 'wkly', 'wo', 'wonderful', 'wont', 'word', 'words', 'work', 'world', 'worried', 'wow', 'wun', 'www', 'xuhui', 'xx', 'xxx', 'xxxmobilemovieclub', 'yeah', 'year', 'yes', 'yesterday', 'yo', 'yummy', 'yup', 'ú1']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model_df.values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which takes an input word and stems it by chopping off its suffix. For the sake of simplicity, consider only words that have the following suffixes: \n",
    "'ing' \n",
    "'ed' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix--> <re.Match object; span=(2, 5), match='ing'>\n",
      "Word--> go\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast, sys\n",
    "word = 'going'\n",
    "\n",
    "# create function to chop off the suffixes 'ing' and 'ed'\n",
    "def stemmer(word):\n",
    "    # write your code here   \n",
    "    pattern = 'ing|ed'\n",
    "    suffix = re.search(pattern, word)\n",
    "    print('Suffix-->',suffix)\n",
    "    word = word[0:suffix.start()]\n",
    "    print('Word-->',word)\n",
    "    return word\n",
    "\n",
    "# stem word -- don't change the following code, it is used to evaluate your code\n",
    "print(stemmer(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Porter stemmer to stem a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garden\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import ast, sys\n",
    "word = 'Gardening'\n",
    "\n",
    "# instantiate porter stemmer\n",
    "stemmer = PorterStemmer()# write code here\n",
    "\n",
    "# stem word\n",
    "stemmed = stemmer.stem(word)# write your code here\n",
    "\n",
    "# print stemmed word -- don't change the following code, it is used to evaluate your code\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem a given word using Snowball stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import ast, sys\n",
    "word = 'coming'\n",
    "\n",
    "# instantiate porter stemmer\n",
    "stemmer = SnowballStemmer(language='english')# write code here\n",
    "\n",
    "# stem word\n",
    "stemmed = stemmer.stem(word)# write code here\n",
    "\n",
    "# print stemmed word -- don't change the following code, it is used to evaluate your code\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize a given word (consider verbs only) using the WordNet Lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import ast, sys\n",
    "word = 'schooling'\n",
    "\n",
    "# instantiate wordnet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()# write code here\n",
    "\n",
    "# lemmatize word\n",
    "lemmatized = lemmatizer.lemmatize(word, pos='v')# write code here. Pass the parameter -> pos='v' to the lemmatize function to lemmatize verbs correctly.\n",
    "\n",
    "# print lemmatized word -- don't change the following code, it is used to evaluate your code\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a set of documents in the code below. Calculate the tf-idf matrix and output the score of the term 'belt' in document two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# consider the following set of documents\n",
    "documents = [\"The coach lumbered on again, with heavier wreaths of mist closing round it as it began the descent.\",\n",
    "             \"The guard soon replaced his blunderbuss in his arm-chest, and, having looked to the rest of its contents, and having looked to the supplementary pistols that he wore in his belt, looked to a smaller chest beneath his seat, in which there were a few smith's tools, a couple of torches, and a tinder-box.\",\n",
    "            \"For he was furnished with that completeness that if the coach-lamps had been blown and stormed out, which did occasionally happen, he had only to shut himself up inside, keep the flint and steel sparks well off the straw, and get a light with tolerable safety and ease (if he were lucky) in five minutes.\",\n",
    "            \"Jerry, left alone in the mist and darkness, dismounted meanwhile, not only to ease his spent horse, but to wipe the mud from his face, and shake the wet out of his hat-brim, which might be capable of holding about half a gallon.\",\n",
    "            \"After standing with the bridle over his heavily-splashed arm, until the wheels of the mail were no longer within hearing and the night was quite still again, he turned to walk down the hill.\"]\n",
    "\n",
    "\n",
    "# preprocess document\n",
    "def preprocess(document):\n",
    "    'changes document to lower case, removes stopwords and stems words'\n",
    "\n",
    "    # change sentence to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize into words\n",
    "    words = word_tokenize(document)\n",
    "\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # stem\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # join words to make sentence\n",
    "    document = \" \".join(words)\n",
    "    \n",
    "    return document\n",
    "\n",
    "# preprocess documents using the preprocess function and store the documents again in a list\n",
    "documents = [preprocess(document) for document in documents]# write code here\n",
    "\n",
    "# create tf-idf matrix\n",
    "## write code here ##\n",
    "tf_idf_vect = TfidfVectorizer()\n",
    "tfidf_model = tf_idf_vect.fit_transform(documents)\n",
    "df = pd.DataFrame(tfidf_model.toarray(), columns = tf_idf_vect.get_feature_names())\n",
    "df\n",
    "# extract score\n",
    "score = 0.175006  # replace -1 with the score of 'belt' in document two. You can manually write the value by looking at the tf_idf model\n",
    "\n",
    "# print the score -- don't change the following piece od code, it's used to evaluate your code\n",
    "print(round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alon</th>\n",
       "      <th>arm</th>\n",
       "      <th>began</th>\n",
       "      <th>belt</th>\n",
       "      <th>beneath</th>\n",
       "      <th>blown</th>\n",
       "      <th>blunderbuss</th>\n",
       "      <th>box</th>\n",
       "      <th>bridl</th>\n",
       "      <th>brim</th>\n",
       "      <th>...</th>\n",
       "      <th>torch</th>\n",
       "      <th>turn</th>\n",
       "      <th>walk</th>\n",
       "      <th>well</th>\n",
       "      <th>wet</th>\n",
       "      <th>wheel</th>\n",
       "      <th>wipe</th>\n",
       "      <th>within</th>\n",
       "      <th>wore</th>\n",
       "      <th>wreath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alon       arm     began      belt   beneath    blown  blunderbuss  \\\n",
       "0  0.000000  0.000000  0.347067  0.000000  0.000000  0.00000     0.000000   \n",
       "1  0.000000  0.141194  0.000000  0.175006  0.175006  0.00000     0.175006   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.20716     0.000000   \n",
       "3  0.216666  0.000000  0.000000  0.000000  0.000000  0.00000     0.000000   \n",
       "4  0.000000  0.203935  0.000000  0.000000  0.000000  0.00000     0.000000   \n",
       "\n",
       "        box     bridl      brim    ...        torch      turn      walk  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.175006  0.000000  0.000000    ...     0.175006  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.216666    ...     0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.252773  0.000000    ...     0.000000  0.252773  0.252773   \n",
       "\n",
       "      well       wet     wheel      wipe    within      wore    wreath  \n",
       "0  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.347067  \n",
       "1  0.00000  0.000000  0.000000  0.000000  0.000000  0.175006  0.000000  \n",
       "2  0.20716  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.00000  0.216666  0.000000  0.216666  0.000000  0.000000  0.000000  \n",
       "4  0.00000  0.000000  0.252773  0.000000  0.252773  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
