{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('A', 'DET'),\n",
       "  ('form', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('once', 'ADV'),\n",
       "  ('used', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('make', 'VERB'),\n",
       "  ('Kent', 'NOUN'),\n",
       "  ('cigarette', 'NOUN'),\n",
       "  ('filters', 'NOUN'),\n",
       "  ('has', 'VERB'),\n",
       "  ('caused', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('high', 'ADJ'),\n",
       "  ('percentage', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('cancer', 'NOUN'),\n",
       "  ('deaths', 'NOUN'),\n",
       "  ('among', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('workers', 'NOUN'),\n",
       "  ('exposed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('more', 'ADV'),\n",
       "  ('than', 'ADP'),\n",
       "  ('30', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('reported', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('asbestos', 'NOUN'),\n",
       "  ('fiber', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('crocidolite', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('is', 'VERB'),\n",
       "  ('unusually', 'ADV'),\n",
       "  ('resilient', 'ADJ'),\n",
       "  ('once', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('enters', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('lungs', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('even', 'ADV'),\n",
       "  ('brief', 'ADJ'),\n",
       "  ('exposures', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('it', 'PRON'),\n",
       "  ('causing', 'VERB'),\n",
       "  ('symptoms', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('show', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('decades', 'NOUN'),\n",
       "  ('later', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('researchers', 'NOUN'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('*T*-2', 'X'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of nltk data:  3914\n"
     ]
    }
   ],
   "source": [
    "print('Size of nltk data: ', len(nltk_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set 2739\n",
      "Size of test set 1175\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(nltk_data, test_size=0.3)\n",
    "print('Size of training set', len(train_set))\n",
    "print('Size of test set', len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_tuples = [tup for sent in train_set for tup in sent]\n",
    "len(train_all_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_words = [tup[0] for tup in train_all_tuples]\n",
    "\n",
    "train_all_tags = [tup[1] for tup in train_all_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of all words:  70256\n",
      "Size of all tags:  70256\n"
     ]
    }
   ],
   "source": [
    "print('Size of all words: ',len(train_all_words))\n",
    "print('Size of all tags: ',len(train_all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of unique words:  10211\n"
     ]
    }
   ],
   "source": [
    "# Find the unique words in the list\n",
    "train_uniq_words = set(train_all_words)\n",
    "print('Size of unique words: ',len(train_uniq_words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of unique tags:  12\n",
      "Tags---> {'VERB', 'PRON', 'ADJ', 'PRT', 'CONJ', 'NOUN', 'ADV', 'NUM', 'X', '.', 'DET', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "# Find the unique tags in the list\n",
    "train_uniq_tags = set(train_all_tags)\n",
    "print('Size of unique tags: ',len(train_uniq_tags)) \n",
    "print('Tags--->', train_uniq_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def calculateEmissionProb(word, tag, train_bag = train_all_tuples):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    prob = count_w_given_tag/count_tag\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00044997750112494374\n"
     ]
    }
   ],
   "source": [
    "print(calculateEmissionProb('man','NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def calculateTransitionProb(t2, t1, train_bag = train_all_tuples):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    prob = count_t2_t1/count_t1\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63787099983419\n"
     ]
    }
   ],
   "source": [
    "print(calculateTransitionProb('NOUN','DET'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(train_uniq_tags), len(train_uniq_tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(train_uniq_tags)):\n",
    "    for j, t2 in enumerate(list(train_uniq_tags)): \n",
    "        tags_matrix[i, j] = calculateTransitionProb(t2,t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tags matrix: (12, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.67451590e-01, 3.52694914e-02, 6.66666701e-02, 3.12925167e-02,\n",
       "        5.86080598e-03, 1.10518053e-01, 8.33071694e-02, 2.16640495e-02,\n",
       "        2.18733653e-01, 3.57927792e-02, 1.31972790e-01, 9.14704353e-02],\n",
       "       [4.90478635e-01, 8.74935649e-03, 7.10241869e-02, 1.49253728e-02,\n",
       "        4.11734451e-03, 2.06896558e-01, 3.34534235e-02, 8.74935649e-03,\n",
       "        8.90375674e-02, 4.16881107e-02, 8.23468901e-03, 2.26453934e-02],\n",
       "       [1.28089888e-02, 4.49438201e-04, 6.47191033e-02, 1.01123592e-02,\n",
       "        1.77528095e-02, 6.97528064e-01, 4.26966278e-03, 1.88764036e-02,\n",
       "        2.13483144e-02, 6.69662952e-02, 4.04494395e-03, 8.11235979e-02],\n",
       "       [4.15480435e-01, 1.73487552e-02, 9.11921710e-02, 2.66903918e-03,\n",
       "        1.77935942e-03, 2.25533813e-01, 9.34163667e-03, 5.42704612e-02,\n",
       "        1.29003562e-02, 4.40391451e-02, 1.02758005e-01, 2.26868335e-02],\n",
       "       [1.63809523e-01, 6.15873002e-02, 1.18095241e-01, 5.71428565e-03,\n",
       "        6.34920609e-04, 3.43492061e-01, 5.46031743e-02, 4.25396822e-02,\n",
       "        8.25396832e-03, 2.92063486e-02, 1.21904761e-01, 5.01587316e-02],\n",
       "       [1.49142548e-01, 4.64976765e-03, 1.12994350e-02, 4.20978963e-02,\n",
       "        4.21478935e-02, 2.64386773e-01, 1.75991207e-02, 9.54952277e-03,\n",
       "        2.96985153e-02, 2.40987957e-01, 1.30993454e-02, 1.75341234e-01],\n",
       "       [3.33186239e-01, 1.45631069e-02, 1.31067961e-01, 1.58870257e-02,\n",
       "        7.94351287e-03, 3.17740515e-02, 8.60547200e-02, 2.95675192e-02,\n",
       "        2.29479261e-02, 1.35922328e-01, 7.01676980e-02, 1.20917916e-01],\n",
       "       [1.92229040e-02, 1.22699386e-03, 3.68098170e-02, 2.74028629e-02,\n",
       "        1.51329245e-02, 3.50102246e-01, 2.45398772e-03, 1.79959103e-01,\n",
       "        2.13905931e-01, 1.14519425e-01, 4.08997945e-03, 3.51738259e-02],\n",
       "       [2.02963918e-01, 5.64862527e-02, 1.56786945e-02, 1.89647764e-01,\n",
       "        1.09536080e-02, 6.52920976e-02, 2.44845357e-02, 3.43642617e-03,\n",
       "        7.47422650e-02, 1.66881442e-01, 5.09020612e-02, 1.38530925e-01],\n",
       "       [8.66303667e-02, 6.64246827e-02, 4.58560176e-02, 2.17785849e-03,\n",
       "        5.69872968e-02, 2.21899584e-01, 5.26315793e-02, 7.99757987e-02,\n",
       "        2.62552928e-02, 9.94555354e-02, 1.73381731e-01, 8.82032663e-02],\n",
       "       [4.14524972e-02, 3.64781963e-03, 1.99469402e-01, 3.31619958e-04,\n",
       "        1.65809979e-04, 6.37871027e-01, 1.34306084e-02, 2.22185384e-02,\n",
       "        4.69242260e-02, 1.80732887e-02, 6.30077953e-03, 1.01144090e-02],\n",
       "       [8.35654605e-03, 7.15437606e-02, 1.06729217e-01, 1.75927288e-03,\n",
       "        8.79636442e-04, 3.20920676e-01, 1.40741831e-02, 6.43600672e-02,\n",
       "        3.50388512e-02, 4.14895192e-02, 3.18721592e-01, 1.61266681e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Size of tags matrix:', tags_matrix.shape)\n",
    "tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VERB</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NUM</th>\n",
       "      <th>X</th>\n",
       "      <th>.</th>\n",
       "      <th>DET</th>\n",
       "      <th>ADP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.167452</td>\n",
       "      <td>0.035269</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.110518</td>\n",
       "      <td>0.083307</td>\n",
       "      <td>0.021664</td>\n",
       "      <td>0.218734</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>0.131973</td>\n",
       "      <td>0.091470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.071024</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.033453</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.089038</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.022645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.064719</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>0.697528</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.066966</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.081124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.415480</td>\n",
       "      <td>0.017349</td>\n",
       "      <td>0.091192</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.225534</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.054270</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.044039</td>\n",
       "      <td>0.102758</td>\n",
       "      <td>0.022687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.163810</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.118095</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.343492</td>\n",
       "      <td>0.054603</td>\n",
       "      <td>0.042540</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.050159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.149143</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.042098</td>\n",
       "      <td>0.042148</td>\n",
       "      <td>0.264387</td>\n",
       "      <td>0.017599</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.029699</td>\n",
       "      <td>0.240988</td>\n",
       "      <td>0.013099</td>\n",
       "      <td>0.175341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.333186</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.131068</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>0.007944</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.086055</td>\n",
       "      <td>0.029568</td>\n",
       "      <td>0.022948</td>\n",
       "      <td>0.135922</td>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.120918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.019223</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.027403</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.179959</td>\n",
       "      <td>0.213906</td>\n",
       "      <td>0.114519</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>0.035174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.202964</td>\n",
       "      <td>0.056486</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.189648</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.065292</td>\n",
       "      <td>0.024485</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>0.074742</td>\n",
       "      <td>0.166881</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.138531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.086630</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>0.045856</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.056987</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.099456</td>\n",
       "      <td>0.173382</td>\n",
       "      <td>0.088203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.199469</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.637871</td>\n",
       "      <td>0.013431</td>\n",
       "      <td>0.022219</td>\n",
       "      <td>0.046924</td>\n",
       "      <td>0.018073</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.010114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.071544</td>\n",
       "      <td>0.106729</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.320921</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>0.064360</td>\n",
       "      <td>0.035039</td>\n",
       "      <td>0.041490</td>\n",
       "      <td>0.318722</td>\n",
       "      <td>0.016127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VERB      PRON       ADJ       PRT      CONJ      NOUN       ADV  \\\n",
       "VERB  0.167452  0.035269  0.066667  0.031293  0.005861  0.110518  0.083307   \n",
       "PRON  0.490479  0.008749  0.071024  0.014925  0.004117  0.206897  0.033453   \n",
       "ADJ   0.012809  0.000449  0.064719  0.010112  0.017753  0.697528  0.004270   \n",
       "PRT   0.415480  0.017349  0.091192  0.002669  0.001779  0.225534  0.009342   \n",
       "CONJ  0.163810  0.061587  0.118095  0.005714  0.000635  0.343492  0.054603   \n",
       "NOUN  0.149143  0.004650  0.011299  0.042098  0.042148  0.264387  0.017599   \n",
       "ADV   0.333186  0.014563  0.131068  0.015887  0.007944  0.031774  0.086055   \n",
       "NUM   0.019223  0.001227  0.036810  0.027403  0.015133  0.350102  0.002454   \n",
       "X     0.202964  0.056486  0.015679  0.189648  0.010954  0.065292  0.024485   \n",
       ".     0.086630  0.066425  0.045856  0.002178  0.056987  0.221900  0.052632   \n",
       "DET   0.041452  0.003648  0.199469  0.000332  0.000166  0.637871  0.013431   \n",
       "ADP   0.008357  0.071544  0.106729  0.001759  0.000880  0.320921  0.014074   \n",
       "\n",
       "           NUM         X         .       DET       ADP  \n",
       "VERB  0.021664  0.218734  0.035793  0.131973  0.091470  \n",
       "PRON  0.008749  0.089038  0.041688  0.008235  0.022645  \n",
       "ADJ   0.018876  0.021348  0.066966  0.004045  0.081124  \n",
       "PRT   0.054270  0.012900  0.044039  0.102758  0.022687  \n",
       "CONJ  0.042540  0.008254  0.029206  0.121905  0.050159  \n",
       "NOUN  0.009550  0.029699  0.240988  0.013099  0.175341  \n",
       "ADV   0.029568  0.022948  0.135922  0.070168  0.120918  \n",
       "NUM   0.179959  0.213906  0.114519  0.004090  0.035174  \n",
       "X     0.003436  0.074742  0.166881  0.050902  0.138531  \n",
       ".     0.079976  0.026255  0.099456  0.173382  0.088203  \n",
       "DET   0.022219  0.046924  0.018073  0.006301  0.010114  \n",
       "ADP   0.064360  0.035039  0.041490  0.318722  0.016127  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_matrix_df = pd.DataFrame(tags_matrix, columns = list(train_uniq_tags), index=list(train_uniq_tags))\n",
    "tags_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_all_tuples):\n",
    "    state = []\n",
    "    T = list(train_uniq_tags)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_matrix_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_matrix_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = calculateEmissionProb(words[key], tag) \n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('20', 'NUM'),\n",
       "  ('billion', 'NUM'),\n",
       "  ('yen', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('6', 'NUM'),\n",
       "  ('%', 'NOUN'),\n",
       "  ('Eurobonds', 'NOUN'),\n",
       "  ('due', 'ADJ'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('21', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('1994', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('priced', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('at', 'ADP'),\n",
       "  ('101', 'NUM'),\n",
       "  ('3\\\\/4', 'NUM'),\n",
       "  ('*', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('yield', 'VERB'),\n",
       "  ('6.03', 'NUM'),\n",
       "  ('%', 'NOUN'),\n",
       "  ('less', 'ADV'),\n",
       "  ('full', 'ADJ'),\n",
       "  ('fees', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('via', 'ADP'),\n",
       "  ('Mitsui', 'NOUN'),\n",
       "  ('Finance', 'NOUN'),\n",
       "  ('International', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('This', 'DET'),\n",
       "  ('is', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('real', 'ADJ'),\n",
       "  ('issue', 'NOUN'),\n",
       "  ('raised', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('Wedtech', 'NOUN'),\n",
       "  ('scandal', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Macmillan\\\\/McGraw', 'NOUN'),\n",
       "  ('says', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('``', '.'),\n",
       "  ('well', 'ADV'),\n",
       "  ('over', 'ADP'),\n",
       "  ('10', 'NUM'),\n",
       "  ('million', 'NUM'),\n",
       "  (\"''\", '.'),\n",
       "  ('of', 'ADP'),\n",
       "  ('its', 'PRON'),\n",
       "  ('Scoring', 'NOUN'),\n",
       "  ('High', 'NOUN'),\n",
       "  ('test-preparation', 'ADJ'),\n",
       "  ('books', 'NOUN'),\n",
       "  ('have', 'VERB'),\n",
       "  ('been', 'VERB'),\n",
       "  ('sold', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('since', 'ADP'),\n",
       "  ('their', 'PRON'),\n",
       "  ('introduction', 'NOUN'),\n",
       "  ('10', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('ago', 'ADV'),\n",
       "  (',', '.'),\n",
       "  ('with', 'ADP'),\n",
       "  ('most', 'ADJ'),\n",
       "  ('sales', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('last', 'ADJ'),\n",
       "  ('five', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('I', 'PRON'),\n",
       "  ('feel', 'VERB'),\n",
       "  ('pretty', 'ADV'),\n",
       "  ('good', 'ADJ'),\n",
       "  ('about', 'ADP'),\n",
       "  ('it', 'PRON'),\n",
       "  ('.', '.')],\n",
       " [('Young', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('Market', 'NOUN'),\n",
       "  ('Co.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('a', 'DET'),\n",
       "  ('wholesaler', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('spirits', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('wines', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('other', 'ADJ'),\n",
       "  ('goods', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('said', 'VERB'),\n",
       "  ('0', 'X'),\n",
       "  ('it', 'PRON'),\n",
       "  ('will', 'VERB'),\n",
       "  ('merge', 'VERB'),\n",
       "  ('with', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('new', 'ADJ'),\n",
       "  ('corporation', 'NOUN'),\n",
       "  ('formed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('Underwood', 'NOUN'),\n",
       "  ('family', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('which', 'DET'),\n",
       "  ('*T*-1', 'X'),\n",
       "  ('controls', 'VERB'),\n",
       "  ('Young', 'NOUN'),\n",
       "  (\"'s\", 'PRT'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  6.838514804840088\n",
      "[('20', 'NUM'), ('billion', 'NUM'), ('yen', 'NOUN'), ('of', 'ADP'), ('6', 'NUM'), ('%', 'NOUN'), ('Eurobonds', 'VERB'), ('due', 'ADJ'), ('Nov.', 'NOUN'), ('21', 'NUM'), (',', '.'), ('1994', 'NUM'), (',', '.'), ('priced', 'VERB'), ('*', 'X'), ('at', 'ADP'), ('101', 'NUM'), ('3\\\\/4', 'NUM'), ('*', 'X'), ('to', 'PRT'), ('yield', 'VERB'), ('6.03', 'VERB'), ('%', 'NOUN'), ('less', 'ADJ'), ('full', 'ADJ'), ('fees', 'NOUN'), (',', '.'), ('via', 'ADP'), ('Mitsui', 'NOUN'), ('Finance', 'NOUN'), ('International', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('real', 'ADJ'), ('issue', 'NOUN'), ('raised', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('the', 'DET'), ('Wedtech', 'NOUN'), ('scandal', 'NOUN'), ('.', '.'), ('Macmillan\\\\/McGraw', 'NOUN'), ('says', 'VERB'), ('0', 'X'), ('``', '.'), ('well', 'ADV'), ('over', 'ADP'), ('10', 'NUM'), ('million', 'NUM'), (\"''\", '.'), ('of', 'ADP'), ('its', 'PRON'), ('Scoring', 'NOUN'), ('High', 'NOUN'), ('test-preparation', 'VERB'), ('books', 'NOUN'), ('have', 'VERB'), ('been', 'VERB'), ('sold', 'VERB'), ('*-1', 'X'), ('since', 'ADP'), ('their', 'PRON'), ('introduction', 'NOUN'), ('10', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('with', 'ADP'), ('most', 'ADJ'), ('sales', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('last', 'ADJ'), ('five', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('I', 'PRON'), ('feel', 'VERB'), ('pretty', 'ADV'), ('good', 'ADJ'), ('about', 'ADP'), ('it', 'PRON'), ('.', '.'), ('Young', 'NOUN'), (\"'s\", 'PRT'), ('Market', 'NOUN'), ('Co.', 'NOUN'), (',', '.'), ('a', 'DET'), ('wholesaler', 'VERB'), ('of', 'ADP'), ('spirits', 'VERB'), (',', '.'), ('wines', 'NOUN'), ('and', 'CONJ'), ('other', 'ADJ'), ('goods', 'NOUN'), (',', '.'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('will', 'VERB'), ('merge', 'VERB'), ('with', 'ADP'), ('a', 'DET'), ('new', 'ADJ'), ('corporation', 'NOUN'), ('formed', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('the', 'DET'), ('Underwood', 'NOUN'), ('family', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('controls', 'NOUN'), ('Young', 'NOUN'), (\"'s\", 'PRT'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = len(check)/len(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349593495934959"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('%', 'NOUN'), (('Eurobonds', 'VERB'), ('Eurobonds', 'NOUN'))],\n",
       " [('yield', 'VERB'), (('6.03', 'VERB'), ('6.03', 'NUM'))],\n",
       " [('%', 'NOUN'), (('less', 'ADJ'), ('less', 'ADV'))],\n",
       " [('High', 'NOUN'),\n",
       "  (('test-preparation', 'VERB'), ('test-preparation', 'ADJ'))],\n",
       " [('years', 'NOUN'), (('ago', 'ADP'), ('ago', 'ADV'))],\n",
       " [('a', 'DET'), (('wholesaler', 'VERB'), ('wholesaler', 'NOUN'))],\n",
       " [('of', 'ADP'), (('spirits', 'VERB'), ('spirits', 'NOUN'))],\n",
       " [('*T*-1', 'X'), (('controls', 'NOUN'), ('controls', 'VERB'))]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = pd.read_csv('sample_test.txt', header=None, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Android is a mobile operating system developed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Android has been the best-selling OS worldwide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google and Twitter made a deal in 2015 that ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter is an online news and social networkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Before entering politics, Donald Trump was a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The 2018 FIFA World Cup is the 21st FIFA World...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is the first World Cup to be held in East...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Show me the cheapest round trips from Dallas t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I would like to see flights from Denver to Phi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Show me the price of the flights leaving Atlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NASA invited social media users to experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   Android is a mobile operating system developed...\n",
       "1   Android has been the best-selling OS worldwide...\n",
       "2   Google and Twitter made a deal in 2015 that ga...\n",
       "3   Twitter is an online news and social networkin...\n",
       "4   Before entering politics, Donald Trump was a d...\n",
       "5   The 2018 FIFA World Cup is the 21st FIFA World...\n",
       "6   This is the first World Cup to be held in East...\n",
       "7   Show me the cheapest round trips from Dallas t...\n",
       "8   I would like to see flights from Denver to Phi...\n",
       "9   Show me the price of the flights leaving Atlan...\n",
       "10  NASA invited social media users to experience ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta',\n",
       " 'I would like to see flights from Denver to Philadelphia.',\n",
       " 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.',\n",
       " 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences_list = list(test_sentences[0])\n",
    "test_sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Android',\n",
       "  'is',\n",
       "  'a',\n",
       "  'mobile',\n",
       "  'operating',\n",
       "  'system',\n",
       "  'developed',\n",
       "  'by',\n",
       "  'Google.'],\n",
       " ['Android',\n",
       "  'has',\n",
       "  'been',\n",
       "  'the',\n",
       "  'best-selling',\n",
       "  'OS',\n",
       "  'worldwide',\n",
       "  'on',\n",
       "  'smartphones',\n",
       "  'since',\n",
       "  '2011',\n",
       "  'and',\n",
       "  'on',\n",
       "  'tablets',\n",
       "  'since',\n",
       "  '2013.'],\n",
       " ['Google',\n",
       "  'and',\n",
       "  'Twitter',\n",
       "  'made',\n",
       "  'a',\n",
       "  'deal',\n",
       "  'in',\n",
       "  '2015',\n",
       "  'that',\n",
       "  'gave',\n",
       "  'Google',\n",
       "  'access',\n",
       "  'to',\n",
       "  \"Twitter's\",\n",
       "  'firehose.'],\n",
       " ['Twitter',\n",
       "  'is',\n",
       "  'an',\n",
       "  'online',\n",
       "  'news',\n",
       "  'and',\n",
       "  'social',\n",
       "  'networking',\n",
       "  'service',\n",
       "  'on',\n",
       "  'which',\n",
       "  'users',\n",
       "  'post',\n",
       "  'and',\n",
       "  'interact',\n",
       "  'with',\n",
       "  'messages',\n",
       "  'known',\n",
       "  'as',\n",
       "  'tweets.'],\n",
       " ['Before',\n",
       "  'entering',\n",
       "  'politics,',\n",
       "  'Donald',\n",
       "  'Trump',\n",
       "  'was',\n",
       "  'a',\n",
       "  'domineering',\n",
       "  'businessman',\n",
       "  'and',\n",
       "  'a',\n",
       "  'television',\n",
       "  'personality.'],\n",
       " ['The',\n",
       "  '2018',\n",
       "  'FIFA',\n",
       "  'World',\n",
       "  'Cup',\n",
       "  'is',\n",
       "  'the',\n",
       "  '21st',\n",
       "  'FIFA',\n",
       "  'World',\n",
       "  'Cup,',\n",
       "  'an',\n",
       "  'international',\n",
       "  'football',\n",
       "  'tournament',\n",
       "  'contested',\n",
       "  'once',\n",
       "  'every',\n",
       "  'four',\n",
       "  'years.'],\n",
       " ['This',\n",
       "  'is',\n",
       "  'the',\n",
       "  'first',\n",
       "  'World',\n",
       "  'Cup',\n",
       "  'to',\n",
       "  'be',\n",
       "  'held',\n",
       "  'in',\n",
       "  'Eastern',\n",
       "  'Europe',\n",
       "  'and',\n",
       "  'the',\n",
       "  '11th',\n",
       "  'time',\n",
       "  'that',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'held',\n",
       "  'in',\n",
       "  'Europe.'],\n",
       " ['Show',\n",
       "  'me',\n",
       "  'the',\n",
       "  'cheapest',\n",
       "  'round',\n",
       "  'trips',\n",
       "  'from',\n",
       "  'Dallas',\n",
       "  'to',\n",
       "  'Atlanta'],\n",
       " ['I',\n",
       "  'would',\n",
       "  'like',\n",
       "  'to',\n",
       "  'see',\n",
       "  'flights',\n",
       "  'from',\n",
       "  'Denver',\n",
       "  'to',\n",
       "  'Philadelphia.'],\n",
       " ['Show',\n",
       "  'me',\n",
       "  'the',\n",
       "  'price',\n",
       "  'of',\n",
       "  'the',\n",
       "  'flights',\n",
       "  'leaving',\n",
       "  'Atlanta',\n",
       "  'at',\n",
       "  'about',\n",
       "  '3',\n",
       "  'in',\n",
       "  'the',\n",
       "  'afternoon',\n",
       "  'and',\n",
       "  'arriving',\n",
       "  'in',\n",
       "  'San',\n",
       "  'Francisco.'],\n",
       " ['NASA',\n",
       "  'invited',\n",
       "  'social',\n",
       "  'media',\n",
       "  'users',\n",
       "  'to',\n",
       "  'experience',\n",
       "  'the',\n",
       "  'launch',\n",
       "  'of',\n",
       "  'ICESAT-2',\n",
       "  'Satellite.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences_list[0]\n",
    "test_all_words = [sent.split() for sent in test_sentences_list]\n",
    "test_all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all_words_list = []\n",
    "for sublist in test_all_words:\n",
    "    for item in sublist:\n",
    "        test_all_words_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android',\n",
       " 'is',\n",
       " 'a',\n",
       " 'mobile',\n",
       " 'operating',\n",
       " 'system',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'Google.',\n",
       " 'Android',\n",
       " 'has',\n",
       " 'been',\n",
       " 'the',\n",
       " 'best-selling',\n",
       " 'OS',\n",
       " 'worldwide',\n",
       " 'on',\n",
       " 'smartphones',\n",
       " 'since',\n",
       " '2011',\n",
       " 'and',\n",
       " 'on',\n",
       " 'tablets',\n",
       " 'since',\n",
       " '2013.',\n",
       " 'Google',\n",
       " 'and',\n",
       " 'Twitter',\n",
       " 'made',\n",
       " 'a',\n",
       " 'deal',\n",
       " 'in',\n",
       " '2015',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'Google',\n",
       " 'access',\n",
       " 'to',\n",
       " \"Twitter's\",\n",
       " 'firehose.',\n",
       " 'Twitter',\n",
       " 'is',\n",
       " 'an',\n",
       " 'online',\n",
       " 'news',\n",
       " 'and',\n",
       " 'social',\n",
       " 'networking',\n",
       " 'service',\n",
       " 'on',\n",
       " 'which',\n",
       " 'users',\n",
       " 'post',\n",
       " 'and',\n",
       " 'interact',\n",
       " 'with',\n",
       " 'messages',\n",
       " 'known',\n",
       " 'as',\n",
       " 'tweets.',\n",
       " 'Before',\n",
       " 'entering',\n",
       " 'politics,',\n",
       " 'Donald',\n",
       " 'Trump',\n",
       " 'was',\n",
       " 'a',\n",
       " 'domineering',\n",
       " 'businessman',\n",
       " 'and',\n",
       " 'a',\n",
       " 'television',\n",
       " 'personality.',\n",
       " 'The',\n",
       " '2018',\n",
       " 'FIFA',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'is',\n",
       " 'the',\n",
       " '21st',\n",
       " 'FIFA',\n",
       " 'World',\n",
       " 'Cup,',\n",
       " 'an',\n",
       " 'international',\n",
       " 'football',\n",
       " 'tournament',\n",
       " 'contested',\n",
       " 'once',\n",
       " 'every',\n",
       " 'four',\n",
       " 'years.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'World',\n",
       " 'Cup',\n",
       " 'to',\n",
       " 'be',\n",
       " 'held',\n",
       " 'in',\n",
       " 'Eastern',\n",
       " 'Europe',\n",
       " 'and',\n",
       " 'the',\n",
       " '11th',\n",
       " 'time',\n",
       " 'that',\n",
       " 'it',\n",
       " 'has',\n",
       " 'been',\n",
       " 'held',\n",
       " 'in',\n",
       " 'Europe.',\n",
       " 'Show',\n",
       " 'me',\n",
       " 'the',\n",
       " 'cheapest',\n",
       " 'round',\n",
       " 'trips',\n",
       " 'from',\n",
       " 'Dallas',\n",
       " 'to',\n",
       " 'Atlanta',\n",
       " 'I',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'see',\n",
       " 'flights',\n",
       " 'from',\n",
       " 'Denver',\n",
       " 'to',\n",
       " 'Philadelphia.',\n",
       " 'Show',\n",
       " 'me',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " 'the',\n",
       " 'flights',\n",
       " 'leaving',\n",
       " 'Atlanta',\n",
       " 'at',\n",
       " 'about',\n",
       " '3',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'and',\n",
       " 'arriving',\n",
       " 'in',\n",
       " 'San',\n",
       " 'Francisco.',\n",
       " 'NASA',\n",
       " 'invited',\n",
       " 'social',\n",
       " 'media',\n",
       " 'users',\n",
       " 'to',\n",
       " 'experience',\n",
       " 'the',\n",
       " 'launch',\n",
       " 'of',\n",
       " 'ICESAT-2',\n",
       " 'Satellite.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_all_words_list)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  9.188700914382935\n",
      "[('Android', 'VERB'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google.', 'VERB'), ('Android', 'VERB'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'VERB'), ('OS', 'VERB'), ('worldwide', 'VERB'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'VERB'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013.', 'VERB'), ('Google', 'VERB'), ('and', 'CONJ'), ('Twitter', 'VERB'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'VERB'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'VERB'), ('access', 'NOUN'), ('to', 'PRT'), (\"Twitter's\", 'VERB'), ('firehose.', 'VERB'), ('Twitter', 'VERB'), ('is', 'VERB'), ('an', 'DET'), ('online', 'VERB'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'VERB'), ('with', 'ADP'), ('messages', 'VERB'), ('known', 'VERB'), ('as', 'ADP'), ('tweets.', 'VERB'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics,', 'VERB'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality.', 'VERB'), ('The', 'DET'), ('2018', 'VERB'), ('FIFA', 'VERB'), ('World', 'NOUN'), ('Cup', 'VERB'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'VERB'), ('FIFA', 'VERB'), ('World', 'NOUN'), ('Cup,', 'VERB'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'VERB'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years.', 'VERB'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'VERB'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe.', 'VERB'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'VERB'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia.', 'VERB'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco.', 'VERB'), ('NASA', 'VERB'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'VERB'), ('Satellite.', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Modification 1 - making emission probability as 1 for words not in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Viterbi_Mod1(words, train_bag = train_all_tuples):\n",
    "    state = []\n",
    "    T = list(train_uniq_tags)\n",
    "    V = list(train_uniq_words)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        \n",
    "        p = [] \n",
    "        \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_matrix_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_matrix_df.loc[state[-1], tag]\n",
    "\n",
    "            # compute emission and state probabilities\n",
    "            if word in V:\n",
    "                emission_p = calculateEmissionProb(words[key], tag) \n",
    "            else:\n",
    "                emission_p = 1\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "        \n",
    "           \n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_Mod1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after first modification:  0.959349593495935\n",
      "incorrect_tagged_cases after first modification:  [[('.', '.'), (('Android', 'NOUN'), ('20', 'NUM'))], [('20', 'NUM'), (('is', 'VERB'), ('billion', 'NUM'))], [('billion', 'NUM'), (('a', 'DET'), ('yen', 'NOUN'))], [('yen', 'NOUN'), (('mobile', 'ADJ'), ('of', 'ADP'))], [('of', 'ADP'), (('operating', 'NOUN'), ('6', 'NUM'))], [('6', 'NUM'), (('system', 'NOUN'), ('%', 'NOUN'))], [('%', 'NOUN'), (('developed', 'VERB'), ('Eurobonds', 'NOUN'))], [('Eurobonds', 'NOUN'), (('by', 'ADP'), ('due', 'ADJ'))], [('due', 'ADJ'), (('Google.', 'NOUN'), ('Nov.', 'NOUN'))], [('Nov.', 'NOUN'), (('Android', 'NOUN'), ('21', 'NUM'))], [('21', 'NUM'), (('has', 'VERB'), (',', '.'))], [(',', '.'), (('been', 'VERB'), ('1994', 'NUM'))], [('1994', 'NUM'), (('the', 'DET'), (',', '.'))], [(',', '.'), (('best-selling', 'NOUN'), ('priced', 'VERB'))], [('priced', 'VERB'), (('OS', 'NOUN'), ('*', 'X'))], [('*', 'X'), (('worldwide', 'NOUN'), ('at', 'ADP'))], [('at', 'ADP'), (('on', 'ADP'), ('101', 'NUM'))], [('101', 'NUM'), (('smartphones', 'NOUN'), ('3\\\\/4', 'NUM'))], [('3\\\\/4', 'NUM'), (('since', 'ADP'), ('*', 'X'))], [('*', 'X'), (('2011', 'NOUN'), ('to', 'PRT'))], [('to', 'PRT'), (('and', 'CONJ'), ('yield', 'VERB'))], [('yield', 'VERB'), (('on', 'ADP'), ('6.03', 'NUM'))], [('6.03', 'NUM'), (('tablets', 'NOUN'), ('%', 'NOUN'))], [('%', 'NOUN'), (('since', 'ADP'), ('less', 'ADV'))], [('less', 'ADV'), (('2013.', 'NOUN'), ('full', 'ADJ'))], [('full', 'ADJ'), (('Google', 'NOUN'), ('fees', 'NOUN'))], [('fees', 'NOUN'), (('and', 'CONJ'), (',', '.'))], [(',', '.'), (('Twitter', 'NOUN'), ('via', 'ADP'))], [('via', 'ADP'), (('made', 'VERB'), ('Mitsui', 'NOUN'))], [('Mitsui', 'NOUN'), (('a', 'DET'), ('Finance', 'NOUN'))], [('Finance', 'NOUN'), (('deal', 'NOUN'), ('International', 'NOUN'))], [('International', 'NOUN'), (('in', 'ADP'), ('.', '.'))], [('.', '.'), (('2015', 'NOUN'), ('This', 'DET'))], [('This', 'DET'), (('that', 'ADP'), ('is', 'VERB'))], [('is', 'VERB'), (('gave', 'VERB'), ('the', 'DET'))], [('the', 'DET'), (('Google', 'X'), ('real', 'ADJ'))], [('real', 'ADJ'), (('access', 'NOUN'), ('issue', 'NOUN'))], [('issue', 'NOUN'), (('to', 'PRT'), ('raised', 'VERB'))], [('raised', 'VERB'), ((\"Twitter's\", 'VERB'), ('*', 'X'))], [('*', 'X'), (('firehose.', 'X'), ('by', 'ADP'))], [('by', 'ADP'), (('Twitter', 'VERB'), ('the', 'DET'))], [('the', 'DET'), (('is', 'VERB'), ('Wedtech', 'NOUN'))], [('Wedtech', 'NOUN'), (('an', 'DET'), ('scandal', 'NOUN'))], [('scandal', 'NOUN'), (('online', 'NOUN'), ('.', '.'))], [('.', '.'), (('news', 'NOUN'), ('Macmillan\\\\/McGraw', 'NOUN'))], [('Macmillan\\\\/McGraw', 'NOUN'), (('and', 'CONJ'), ('says', 'VERB'))], [('says', 'VERB'), (('social', 'ADJ'), ('0', 'X'))], [('0', 'X'), (('networking', 'NOUN'), ('``', '.'))], [('``', '.'), (('service', 'NOUN'), ('well', 'ADV'))], [('well', 'ADV'), (('on', 'ADP'), ('over', 'ADP'))], [('over', 'ADP'), (('which', 'DET'), ('10', 'NUM'))], [('10', 'NUM'), (('users', 'NOUN'), ('million', 'NUM'))], [('million', 'NUM'), (('post', 'NOUN'), (\"''\", '.'))], [(\"''\", '.'), (('and', 'CONJ'), ('of', 'ADP'))], [('of', 'ADP'), (('interact', 'NOUN'), ('its', 'PRON'))], [('its', 'PRON'), (('with', 'ADP'), ('Scoring', 'NOUN'))], [('Scoring', 'NOUN'), (('messages', 'NOUN'), ('High', 'NOUN'))], [('High', 'NOUN'), (('known', 'VERB'), ('test-preparation', 'ADJ'))], [('test-preparation', 'ADJ'), (('as', 'ADP'), ('books', 'NOUN'))], [('books', 'NOUN'), (('tweets.', 'NOUN'), ('have', 'VERB'))], [('have', 'VERB'), (('Before', 'ADP'), ('been', 'VERB'))], [('been', 'VERB'), (('entering', 'VERB'), ('sold', 'VERB'))], [('sold', 'VERB'), (('politics,', 'X'), ('*-1', 'X'))], [('*-1', 'X'), (('Donald', 'NOUN'), ('since', 'ADP'))], [('since', 'ADP'), (('Trump', 'NOUN'), ('their', 'PRON'))], [('their', 'PRON'), (('was', 'VERB'), ('introduction', 'NOUN'))], [('introduction', 'NOUN'), (('a', 'DET'), ('10', 'NUM'))], [('10', 'NUM'), (('domineering', 'NOUN'), ('years', 'NOUN'))], [('years', 'NOUN'), (('businessman', 'NOUN'), ('ago', 'ADV'))], [('ago', 'ADV'), (('and', 'CONJ'), (',', '.'))], [(',', '.'), (('a', 'DET'), ('with', 'ADP'))], [('with', 'ADP'), (('television', 'NOUN'), ('most', 'ADJ'))], [('most', 'ADJ'), (('personality.', 'NOUN'), ('sales', 'NOUN'))], [('sales', 'NOUN'), (('The', 'DET'), ('in', 'ADP'))], [('in', 'ADP'), (('2018', 'NOUN'), ('the', 'DET'))], [('the', 'DET'), (('FIFA', 'NOUN'), ('last', 'ADJ'))], [('last', 'ADJ'), (('World', 'NOUN'), ('five', 'NUM'))], [('five', 'NUM'), (('Cup', 'NOUN'), ('years', 'NOUN'))], [('years', 'NOUN'), (('is', 'VERB'), ('.', '.'))], [('.', '.'), (('the', 'DET'), ('I', 'PRON'))], [('I', 'PRON'), (('21st', 'NOUN'), ('feel', 'VERB'))], [('feel', 'VERB'), (('FIFA', 'NOUN'), ('pretty', 'ADV'))], [('pretty', 'ADV'), (('World', 'NOUN'), ('good', 'ADJ'))], [('good', 'ADJ'), (('Cup,', 'NOUN'), ('about', 'ADP'))], [('about', 'ADP'), (('an', 'DET'), ('it', 'PRON'))], [('it', 'PRON'), (('international', 'ADJ'), ('.', '.'))], [('.', '.'), (('football', 'NOUN'), ('Young', 'NOUN'))], [('Young', 'NOUN'), (('tournament', 'NOUN'), (\"'s\", 'PRT'))], [(\"'s\", 'PRT'), (('contested', 'NOUN'), ('Market', 'NOUN'))], [('Market', 'NOUN'), (('once', 'ADV'), ('Co.', 'NOUN'))], [('Co.', 'NOUN'), (('every', 'DET'), (',', '.'))], [(',', '.'), (('four', 'NUM'), ('a', 'DET'))], [('a', 'DET'), (('years.', 'NOUN'), ('wholesaler', 'NOUN'))], [('wholesaler', 'NOUN'), (('This', 'DET'), ('of', 'ADP'))], [('of', 'ADP'), (('is', 'VERB'), ('spirits', 'NOUN'))], [('spirits', 'NOUN'), (('the', 'DET'), (',', '.'))], [(',', '.'), (('first', 'ADJ'), ('wines', 'NOUN'))], [('wines', 'NOUN'), (('World', 'NOUN'), ('and', 'CONJ'))], [('and', 'CONJ'), (('Cup', 'NOUN'), ('other', 'ADJ'))], [('other', 'ADJ'), (('to', 'PRT'), ('goods', 'NOUN'))], [('goods', 'NOUN'), (('be', 'VERB'), (',', '.'))], [(',', '.'), (('held', 'VERB'), ('said', 'VERB'))], [('said', 'VERB'), (('in', 'ADP'), ('0', 'X'))], [('0', 'X'), (('Eastern', 'NOUN'), ('it', 'PRON'))], [('it', 'PRON'), (('Europe', 'NOUN'), ('will', 'VERB'))], [('will', 'VERB'), (('and', 'CONJ'), ('merge', 'VERB'))], [('merge', 'VERB'), (('the', 'DET'), ('with', 'ADP'))], [('with', 'ADP'), (('11th', 'ADJ'), ('a', 'DET'))], [('a', 'DET'), (('time', 'NOUN'), ('new', 'ADJ'))], [('new', 'ADJ'), (('that', 'ADP'), ('corporation', 'NOUN'))], [('corporation', 'NOUN'), (('it', 'PRON'), ('formed', 'VERB'))], [('formed', 'VERB'), (('has', 'VERB'), ('*', 'X'))], [('*', 'X'), (('been', 'VERB'), ('by', 'ADP'))], [('by', 'ADP'), (('held', 'VERB'), ('the', 'DET'))], [('the', 'DET'), (('in', 'ADP'), ('Underwood', 'NOUN'))], [('Underwood', 'NOUN'), (('Europe.', 'NOUN'), ('family', 'NOUN'))], [('family', 'NOUN'), (('Show', 'NOUN'), (',', '.'))], [(',', '.'), (('me', 'PRON'), ('which', 'DET'))], [('which', 'DET'), (('the', 'DET'), ('*T*-1', 'X'))], [('*T*-1', 'X'), (('cheapest', 'ADJ'), ('controls', 'VERB'))], [('controls', 'VERB'), (('round', 'NOUN'), ('Young', 'NOUN'))], [('Young', 'NOUN'), (('trips', 'NOUN'), (\"'s\", 'PRT'))], [(\"'s\", 'PRT'), (('from', 'ADP'), ('.', '.'))]]\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "print ('Accuracy after first modification: ', accuracy)\n",
    "\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(test_tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "\n",
    "print ('incorrect_tagged_cases after first modification: ', incorrect_tagged_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tag list of the test sentences are: \n",
      " [('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google.', 'NOUN'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'NOUN'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013.', 'NOUN'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NOUN'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), (\"Twitter's\", 'VERB'), ('firehose.', 'X'), ('Twitter', 'VERB'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'NOUN'), ('known', 'VERB'), ('as', 'ADP'), ('tweets.', 'NOUN'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics,', 'X'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality.', 'NOUN'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup,', 'NOUN'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years.', 'NOUN'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe.', 'NOUN'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia.', 'VERB'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'NOUN'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco.', 'NOUN'), ('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite.', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "test_tagged_seq = Viterbi_Mod1(test_all_words_list)\n",
    "print('The tag list of the test sentences are: \\n', test_tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Modification 2 - adding regular expressions for words not in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viterbi Modification 2 - adding regular expressions for words not in vocabulary\n",
    "\n",
    "\n",
    "def Viterbi_Mod2(words, train_bag = train_all_tuples):\n",
    "    state = []\n",
    "    T = list(train_uniq_tags)\n",
    "    V = list(train_uniq_words)\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        if word in V:\n",
    "            p = [] \n",
    "\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_matrix_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_matrix_df.loc[state[-1], tag]\n",
    "\n",
    "                # compute emission and state probabilities\n",
    "                if word in V:\n",
    "                    emission_p = calculateEmissionProb(words[key], tag) \n",
    "                else:\n",
    "                    emission_p = 1\n",
    "                state_probability = emission_p * transition_p    \n",
    "                p.append(state_probability)\n",
    "            pmax = max(p)\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)]\n",
    "        else:\n",
    "            if re.match(r'.*ing$',word):\n",
    "                state_max='VBG'       # gerunds\n",
    "            elif re.match(r'.*ed$',word):\n",
    "                state_max='VBD' # simple past\n",
    "            elif re.match(r'.*es$',word):\n",
    "                state_max='VBZ'\n",
    "            elif re.match(r'.*ould$',word):\n",
    "                state_max='MD'\n",
    "            elif re.match(r'.*\\'s$',word):\n",
    "                state_max='NN$'\n",
    "            elif re.match(r'^-?[0-9]+(.[0-9]+)?$',word):\n",
    "                state_max='NUM'\n",
    "            else:\n",
    "                state_max='NOUN'\n",
    "            \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_Mod2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after second modification:  0.967479674796748\n",
      "\n",
      "\n",
      " incorrect_tagged_cases after second modification:  [[('.', '.'), (('Android', 'NOUN'), ('20', 'NUM'))], [('20', 'NUM'), (('is', 'VERB'), ('billion', 'NUM'))], [('billion', 'NUM'), (('a', 'DET'), ('yen', 'NOUN'))], [('yen', 'NOUN'), (('mobile', 'ADJ'), ('of', 'ADP'))], [('of', 'ADP'), (('operating', 'NOUN'), ('6', 'NUM'))], [('6', 'NUM'), (('system', 'NOUN'), ('%', 'NOUN'))], [('%', 'NOUN'), (('developed', 'VERB'), ('Eurobonds', 'NOUN'))], [('Eurobonds', 'NOUN'), (('by', 'ADP'), ('due', 'ADJ'))], [('due', 'ADJ'), (('Google.', 'NOUN'), ('Nov.', 'NOUN'))], [('Nov.', 'NOUN'), (('Android', 'NOUN'), ('21', 'NUM'))], [('21', 'NUM'), (('has', 'VERB'), (',', '.'))], [(',', '.'), (('been', 'VERB'), ('1994', 'NUM'))], [('1994', 'NUM'), (('the', 'DET'), (',', '.'))], [(',', '.'), (('best-selling', 'NOUN'), ('priced', 'VERB'))], [('priced', 'VERB'), (('OS', 'NOUN'), ('*', 'X'))], [('*', 'X'), (('worldwide', 'NOUN'), ('at', 'ADP'))], [('at', 'ADP'), (('on', 'ADP'), ('101', 'NUM'))], [('101', 'NUM'), (('smartphones', 'NOUN'), ('3\\\\/4', 'NUM'))], [('3\\\\/4', 'NUM'), (('since', 'ADP'), ('*', 'X'))], [('*', 'X'), (('2011', 'NOUN'), ('to', 'PRT'))], [('to', 'PRT'), (('and', 'CONJ'), ('yield', 'VERB'))], [('yield', 'VERB'), (('on', 'ADP'), ('6.03', 'NUM'))], [('6.03', 'NUM'), (('tablets', 'NOUN'), ('%', 'NOUN'))], [('%', 'NOUN'), (('since', 'ADP'), ('less', 'ADV'))], [('less', 'ADV'), (('2013.', 'NOUN'), ('full', 'ADJ'))], [('full', 'ADJ'), (('Google', 'NOUN'), ('fees', 'NOUN'))], [('fees', 'NOUN'), (('and', 'CONJ'), (',', '.'))], [(',', '.'), (('Twitter', 'NOUN'), ('via', 'ADP'))], [('via', 'ADP'), (('made', 'VERB'), ('Mitsui', 'NOUN'))], [('Mitsui', 'NOUN'), (('a', 'DET'), ('Finance', 'NOUN'))], [('Finance', 'NOUN'), (('deal', 'NOUN'), ('International', 'NOUN'))], [('International', 'NOUN'), (('in', 'ADP'), ('.', '.'))], [('.', '.'), (('2015', 'NOUN'), ('This', 'DET'))], [('This', 'DET'), (('that', 'ADP'), ('is', 'VERB'))], [('is', 'VERB'), (('gave', 'VERB'), ('the', 'DET'))], [('the', 'DET'), (('Google', 'X'), ('real', 'ADJ'))], [('real', 'ADJ'), (('access', 'NOUN'), ('issue', 'NOUN'))], [('issue', 'NOUN'), (('to', 'PRT'), ('raised', 'VERB'))], [('raised', 'VERB'), ((\"Twitter's\", 'VERB'), ('*', 'X'))], [('*', 'X'), (('firehose.', 'X'), ('by', 'ADP'))], [('by', 'ADP'), (('Twitter', 'VERB'), ('the', 'DET'))], [('the', 'DET'), (('is', 'VERB'), ('Wedtech', 'NOUN'))], [('Wedtech', 'NOUN'), (('an', 'DET'), ('scandal', 'NOUN'))], [('scandal', 'NOUN'), (('online', 'NOUN'), ('.', '.'))], [('.', '.'), (('news', 'NOUN'), ('Macmillan\\\\/McGraw', 'NOUN'))], [('Macmillan\\\\/McGraw', 'NOUN'), (('and', 'CONJ'), ('says', 'VERB'))], [('says', 'VERB'), (('social', 'ADJ'), ('0', 'X'))], [('0', 'X'), (('networking', 'NOUN'), ('``', '.'))], [('``', '.'), (('service', 'NOUN'), ('well', 'ADV'))], [('well', 'ADV'), (('on', 'ADP'), ('over', 'ADP'))], [('over', 'ADP'), (('which', 'DET'), ('10', 'NUM'))], [('10', 'NUM'), (('users', 'NOUN'), ('million', 'NUM'))], [('million', 'NUM'), (('post', 'NOUN'), (\"''\", '.'))], [(\"''\", '.'), (('and', 'CONJ'), ('of', 'ADP'))], [('of', 'ADP'), (('interact', 'NOUN'), ('its', 'PRON'))], [('its', 'PRON'), (('with', 'ADP'), ('Scoring', 'NOUN'))], [('Scoring', 'NOUN'), (('messages', 'NOUN'), ('High', 'NOUN'))], [('High', 'NOUN'), (('known', 'VERB'), ('test-preparation', 'ADJ'))], [('test-preparation', 'ADJ'), (('as', 'ADP'), ('books', 'NOUN'))], [('books', 'NOUN'), (('tweets.', 'NOUN'), ('have', 'VERB'))], [('have', 'VERB'), (('Before', 'ADP'), ('been', 'VERB'))], [('been', 'VERB'), (('entering', 'VERB'), ('sold', 'VERB'))], [('sold', 'VERB'), (('politics,', 'X'), ('*-1', 'X'))], [('*-1', 'X'), (('Donald', 'NOUN'), ('since', 'ADP'))], [('since', 'ADP'), (('Trump', 'NOUN'), ('their', 'PRON'))], [('their', 'PRON'), (('was', 'VERB'), ('introduction', 'NOUN'))], [('introduction', 'NOUN'), (('a', 'DET'), ('10', 'NUM'))], [('10', 'NUM'), (('domineering', 'NOUN'), ('years', 'NOUN'))], [('years', 'NOUN'), (('businessman', 'NOUN'), ('ago', 'ADV'))], [('ago', 'ADV'), (('and', 'CONJ'), (',', '.'))], [(',', '.'), (('a', 'DET'), ('with', 'ADP'))], [('with', 'ADP'), (('television', 'NOUN'), ('most', 'ADJ'))], [('most', 'ADJ'), (('personality.', 'NOUN'), ('sales', 'NOUN'))], [('sales', 'NOUN'), (('The', 'DET'), ('in', 'ADP'))], [('in', 'ADP'), (('2018', 'NOUN'), ('the', 'DET'))], [('the', 'DET'), (('FIFA', 'NOUN'), ('last', 'ADJ'))], [('last', 'ADJ'), (('World', 'NOUN'), ('five', 'NUM'))], [('five', 'NUM'), (('Cup', 'NOUN'), ('years', 'NOUN'))], [('years', 'NOUN'), (('is', 'VERB'), ('.', '.'))], [('.', '.'), (('the', 'DET'), ('I', 'PRON'))], [('I', 'PRON'), (('21st', 'NOUN'), ('feel', 'VERB'))], [('feel', 'VERB'), (('FIFA', 'NOUN'), ('pretty', 'ADV'))], [('pretty', 'ADV'), (('World', 'NOUN'), ('good', 'ADJ'))], [('good', 'ADJ'), (('Cup,', 'NOUN'), ('about', 'ADP'))], [('about', 'ADP'), (('an', 'DET'), ('it', 'PRON'))], [('it', 'PRON'), (('international', 'ADJ'), ('.', '.'))], [('.', '.'), (('football', 'NOUN'), ('Young', 'NOUN'))], [('Young', 'NOUN'), (('tournament', 'NOUN'), (\"'s\", 'PRT'))], [(\"'s\", 'PRT'), (('contested', 'NOUN'), ('Market', 'NOUN'))], [('Market', 'NOUN'), (('once', 'ADV'), ('Co.', 'NOUN'))], [('Co.', 'NOUN'), (('every', 'DET'), (',', '.'))], [(',', '.'), (('four', 'NUM'), ('a', 'DET'))], [('a', 'DET'), (('years.', 'NOUN'), ('wholesaler', 'NOUN'))], [('wholesaler', 'NOUN'), (('This', 'DET'), ('of', 'ADP'))], [('of', 'ADP'), (('is', 'VERB'), ('spirits', 'NOUN'))], [('spirits', 'NOUN'), (('the', 'DET'), (',', '.'))], [(',', '.'), (('first', 'ADJ'), ('wines', 'NOUN'))], [('wines', 'NOUN'), (('World', 'NOUN'), ('and', 'CONJ'))], [('and', 'CONJ'), (('Cup', 'NOUN'), ('other', 'ADJ'))], [('other', 'ADJ'), (('to', 'PRT'), ('goods', 'NOUN'))], [('goods', 'NOUN'), (('be', 'VERB'), (',', '.'))], [(',', '.'), (('held', 'VERB'), ('said', 'VERB'))], [('said', 'VERB'), (('in', 'ADP'), ('0', 'X'))], [('0', 'X'), (('Eastern', 'NOUN'), ('it', 'PRON'))], [('it', 'PRON'), (('Europe', 'NOUN'), ('will', 'VERB'))], [('will', 'VERB'), (('and', 'CONJ'), ('merge', 'VERB'))], [('merge', 'VERB'), (('the', 'DET'), ('with', 'ADP'))], [('with', 'ADP'), (('11th', 'ADJ'), ('a', 'DET'))], [('a', 'DET'), (('time', 'NOUN'), ('new', 'ADJ'))], [('new', 'ADJ'), (('that', 'ADP'), ('corporation', 'NOUN'))], [('corporation', 'NOUN'), (('it', 'PRON'), ('formed', 'VERB'))], [('formed', 'VERB'), (('has', 'VERB'), ('*', 'X'))], [('*', 'X'), (('been', 'VERB'), ('by', 'ADP'))], [('by', 'ADP'), (('held', 'VERB'), ('the', 'DET'))], [('the', 'DET'), (('in', 'ADP'), ('Underwood', 'NOUN'))], [('Underwood', 'NOUN'), (('Europe.', 'NOUN'), ('family', 'NOUN'))], [('family', 'NOUN'), (('Show', 'NOUN'), (',', '.'))], [(',', '.'), (('me', 'PRON'), ('which', 'DET'))], [('which', 'DET'), (('the', 'DET'), ('*T*-1', 'X'))], [('*T*-1', 'X'), (('cheapest', 'ADJ'), ('controls', 'VERB'))], [('controls', 'VERB'), (('round', 'NOUN'), ('Young', 'NOUN'))], [('Young', 'NOUN'), (('trips', 'NOUN'), (\"'s\", 'PRT'))], [(\"'s\", 'PRT'), (('from', 'ADP'), ('.', '.'))]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'the label [VBZ] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1789\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m                     \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1784\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1785\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [VBZ] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-cd8d71c07824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n incorrect_tagged_cases after second modification: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincorrect_tagged_cases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtest_tagged_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mViterbi_Mod2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_all_words_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The tag list of the test sentences are: \\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_tagged_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-866e8d0818d9>\u001b[0m in \u001b[0;36mViterbi_Mod2\u001b[1;34m(words, train_bag)\u001b[0m\n\u001b[0;32m     16\u001b[0m                     \u001b[0mtransition_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtags_matrix_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                     \u001b[0mtransition_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtags_matrix_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;31m# compute emission and state probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1783\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[0;32m   1784\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1785\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [VBZ] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "print ('Accuracy after second modification: ', accuracy)\n",
    "\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(test_tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "\n",
    "print ('\\n\\n incorrect_tagged_cases after second modification: ', incorrect_tagged_cases)\n",
    "\n",
    "test_tagged_seq = Viterbi_Mod2(test_all_words_list)\n",
    "print('The tag list of the test sentences are: \\n', test_tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
