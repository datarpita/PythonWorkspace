{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_excel('data/Raw_Data_TechDebt.xlsx', sheet_name='DebtInfo_246')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Debt_Description</th>\n",
       "      <th>Debt_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPS tries to push script packets and scripts f...</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normalization failure -  SAP sytem sends dupli...</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metrica monitoring issue - issue were raised b...</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unable to withdraw entries becasue related scr...</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eSpecial Consideration website does not open f...</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SPJNTAP040 Apache server issues leading to hos...</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prep Centre's status is 'Access granted' but p...</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A centre have uploaded work to the repository,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>User unable to merge candidate in CAMS Admin d...</td>\n",
       "      <td>Operational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A number of results for UKVI are not flowing f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Debt_Description   Debt_Class\n",
       "0  EPS tries to push script packets and scripts f...    Technical\n",
       "1  Normalization failure -  SAP sytem sends dupli...    Technical\n",
       "2  Metrica monitoring issue - issue were raised b...    Technical\n",
       "3  Unable to withdraw entries becasue related scr...    Technical\n",
       "4  eSpecial Consideration website does not open f...    Technical\n",
       "5  SPJNTAP040 Apache server issues leading to hos...    Technical\n",
       "6  Prep Centre's status is 'Access granted' but p...    Technical\n",
       "7  A centre have uploaded work to the repository,...          NaN\n",
       "8  User unable to merge candidate in CAMS Admin d...  Operational\n",
       "9  A number of results for UKVI are not flowing f...          NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = raw_data.loc[raw_data['Debt_Class'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_grp = processed_data.groupby(by='Debt_Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Debt_Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debt_Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Functional</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Knowledge</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operational</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technical</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Debt_Description\n",
       "Debt_Class                   \n",
       "Functional                 34\n",
       "Knowledge                   7\n",
       "Operational                15\n",
       "Technical                 190"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_grp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x691c8080>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data['Debt_Class'].value_counts().plot(kind='pie', figsize=(5,5), autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dattaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dattaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dattaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dattaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(processed_data['Debt_Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialise the inbuilt Stemmer and the Lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eps try push script packets script non activate sessions sts', 'normalization failure sap sytem send duplicate script sts result job failure sts', 'metrica monitor issue issue raise elit speak api directly try test data pre production environment', 'unable withdraw entries becasue relate script packets exist eps', 'especial consideration website open users intermittently', 'spjntap apache server issue lead host application connectivity problems', 'prep centre status access grant prep centre user still able login', 'user unable merge candidate cams admin due data cams interchange', 'statement result generate ceo candidate result application', 'claim grade achievement addition deletion interchange', 'request delete examiner ems application', 'problem load entry file pdq module cca series', 'problem data fee eps sts half hourly refresh job wrong packet id tag script data', 'record process suspense', 'cams gti suspense application error', 'apache service report intermittent errors indicate potencial issue application server', 'clms candidates able launch test second attempt', 'try merge candidate use account merge functionality metrica user unable merge encounter error', 'metrica return code receive within hours speech submission action', 'oms application open users due ms access database corruption', 'need functionality ams application add users directly ams database active directory', 'spstsap spstsap service alert', 'unable suspend access prepcentres previously delete prepcentre fullname', 'problem ms ole object error occur open test task document help ole object', 'error import file cams', 'sts half hourly job failure due wrong fee link pr', 'request add gti entry type', 'interchange candidates appear claim upload spreadsheet', 'cams allocation unable send allocation moderator', 'user unable login cm site due issue pyodbc adaptor resolve reset adaptor', 'metrica site unavailable due redis cache work', 'monitor alert receive indicate erepository site available', 'error asp extract sap', 'cams award issue cams award encounter couple failures', 'cams caap record center date stamp unlock', 'request add achievements certificate', 'bulats token issue add delete update reset token', 'sts application temporarily unavailable slow', 'error code display launch test use entry code', 'claim stick finalize status multiple reason', 'cie direct performance degrated due multiple entries upload center', 'especial consideration website open users intermittently', 'lower examiner asfa admin need delete root examiner get delete avoid duplicate entries asfa portal', 'problem create new user email address validation', 'cams internal service alert call permissions change folder cams apps cams admin server spcamap ucles internal', 'esm mark aggregation count high', 'issue download metrica media file', 'candidate unable register ceas file manager application https candidates cambridgeenglish org', 'bulats production database configuration value get change', 'spreadsheet generate eps load products screen mprd muat environment', 'metrica camla application due incorrectly format resource file', 'functional skills marksheet user want remove marksheets', 'candidate result online unable register', 'esm access script bulk upload failure report', 'request run report result comparison', 'different claim get update moderator sample submit claim', 'apo often receive require huge number add removal examiners particular centre status role change functionality need add address', 'candidates claim visible moderator review claim area', 'ats result online centre issue result csv tsa tmua', 'ceo candidate result service get frequently', 'ceo screen freeze click submit select entries menu option chrome', 'libs use office open word document windows citrix create issue open word document', 'test start log log tokens though candidate complete test successfully', 'enquiries key examiner actual end date show result enquiry screen eps prevent enquiry close', 'candidate entries stick process status cie direct however eps validate process', 'esolcp push fail whenever eps delete centre', 'especial consideration website open users intermittently', 'problem import edi test entry file gti entries create cams fee entries interchange', 'problem multipart packets part number yellow label packets', 'functionality available correct errors make examiners mark', 'rat manager export service take huge time execute result rat miss eps transfer time slot', 'annual request data se qualifications', 'incorrect data show sometimes pass fail report', 'ceo prep center data issue prep centre access result chart past fce school candidates', 'ems password reset request', 'packets present sts application', 'cie direct application', 'grade mark change check mu mu', 'scan allocation issue sts allocation complete eps seem feed sts half hourly refresh', 'article number generate ams show scale prevent process', 'candidates able register portal use helpdesk cambridgeenglish org cambridgeenglishonline cambridgeenglish org reply cambridgeenglish org allow', 'claim import cams arf interchange without units', 'problem auto capitaliztion feature candidate name get atuo update upper case', 'entries extranet app servers generate alert stdout log file big', 'adip grade issue inconsistent grade grade lower environments compare mprd', 'admin page entries extranet show blank screen', 'clms integration issue data score send clms metrica', 'syllabus miss generate statement result candidates take group award', 'centre able raise access script enquiry component', 'candidates miss candidate specification breakdown report j', 'cumulative specification report result document area interchange run correctly', 'scenarios modify option available respective release date candidates centre universities', 'first time center set doesnt flow eps ems automatically apo need set manually ems database', 'issue timer behaviour test result additional time available candidates', 'candidate number filtration work search script functionality', 'metrica clms audio resume launch clms site', 'request unlock record cams application', 'unable download sor report', 'bulats zd account deactivate recertification yet complete', 'checkpoint http ciecheckpoint ucles org uk', 'anonymous session reference copy firefox', 'test multiple content cause error anonymous test', 'user role allow access application message upon log https repository ocr org uk', 'best pixel size need import equations svg file metrica', 'bulk allocation notification mail examiner job role type need supressed', 'candidate assignment get update wrong data create data anomaly', 'candidate registration even user select one two candidates export button still try export record', 'candidate result service create blank sor xmls intermittently', 'candidates see blank question number field mcl content type number mode test section disable', 'candidates receive survey invitation email candidates result portal', 'carnegie automarker return error audio file less second', 'ce admin resend responses elit responses', 'centre access detail special consider applications', 'cis screen test save data database intermittently', 'click cancel select add session user take session list page', 'client users institution see location venues main institution create session', 'clms receive score progress metrica', 'content configuration page show hour ahead current time', 'content production users face errors add discrimination facility difficulty attribute test level inside test detail page', 'content type split view work properly items content production', 'coursework mark submit centre enter coursework mark screen change', 'customer would like add change logic reschedule book button appear candidate', 'daily extract report identify items escaleted error generate manually need add functionality applciation', 'remove child node approval warn eps session review screen', 'daily report detail units centre review moderation report generate manually need add functionality applciation', 'data size limit tii_data column test_instance_integration table need increase', 'incorrect amount appear invoice sap due incorrect amount send eps', 'difficulty attribute items display correct value content production site', 'problem coda invoice file cams export check digit miss', 'unwanted link available cm message section reason', 'ems run ucles id prevent user process new speak examiner nominations', 'scale rank order violation lighlighted eps scale screen', 'error convert image particular items metrica content production', 'nowait error raise processign scolarship eps', 'esm connections libs databse handle properly connections persist release result oracle exception', 'esm invalid mark cleb use aggregation rather valid mark imrb', 'examiner certification test open old display style', 'examiner flag issue sound quality number candidates linguaskill east asia march session', 'eps error warn message user try withdraw candidates manual grade', 'failure plr uln validation lrs due higher batchsize', 'fao metrica apo team drop menu shwoing correct value session group', 'filter problem content admin', 'format error invoice read listen test', 'caap application freeze result determination process', 'full mark report every centre unit comp specific session generate manually need add functionality applciation', 'user metrica create ampersand character allow user login metrica portal', 'image get overlap add items content production', 'active result raw mark actually raw mark unit r instead subject j hence raw mark match specifications', 'content production site items comment get truncate cause data loss', 'incorrect aggregation calculation flag question responses candidates', 'incorrect letter alignment appear test items content production', 'interchange moderator able withdraw candidate process claim', 'interchange unable make full entry candidates already enter different scheme family', 'interchange moderators receive email multiple time submission claim centre', 'libs qprd preview report show wrong total mark', 'interchange one moderators able edit claim', 'invalid character appear confirmation entry template', 'input folder go miss cause users unable import test entries gti cams', 'master moderation progress report centre components generate manually need add functionality applciation', 'problem ce libs publish markschemes automarker evo task', 'metrica export key button longer present sessions detail page', 'metrica mark session page image show question', 'metrica deletion client institutuion affect total count licence institution', 'metrica admin camla wild card accept filter items test usage current stage attribute', 'incorrect team position displaued otp result enquiry grade change screen', 'metrica admin report time try view', 'metrica admin run time errors view test', 'dmas spjntor service outage due network stack failure', 'problem purge task functionality task publish automarker', 'sts exist job item record logic miss half hourly job sts eps', 'metrica test balance show incorrect value institutions', 'metrica test publish issue adaptive test large number items', 'moderators unable access ocr repository', 'problem save cb ielts task evo functionality', 'modman eps consortium centre process eps regression', 'eps able display validation message user try freeze syllabus grade area', 'problem purge test copy remove document original test', 'incorrect group assign syllabus grade adip', 'land page need candiate centre sub page https result cambridgeassessment org uk site', 'audit record create mark release result enquiry eps', 'exist code login cams centre invoice extract fail check digit miss', 'new sessions add active already suspend session group', 'problem candidate entries certain assessement course college observe duplicate entries back', 'libs attribute report end database error', 'validation stop duplicate entries upload', 'able save update timer candidates stay current question longer time refresh test', 'online anonymous test work adaptive test', 'page refresh happen mark session creation', 'pagination filtration attribute work properly content production', 'parent creditor id ocr erepository get wrongly update', 'pm unable run full mark report component level', 'portal users get system error audit screen', 'certificate number print certificate different number store eps', 'preparation centre name contain greek character update question mark ceo', 'project field isnt consider filter result items project select combination items pre define filter', 'report moderation reversion identify moderators submission review worklist generate manually need add functionality applciation', 'report need generate file uploded data specific session', 'resending email button bmat non imat book ids fail send email candidates', 'review improve metrica clms score transfer process', 'ror outcome email go intermittently', 'ror screen show n instead mark outcome email get send old session', 'e spec con entries appear eps syllabus', 'session import esm fail every monday morning due eps downtime', 'simulataneous request biztalk upload mark eps often result duplicate mark upload candidate eps', 'items throw error metrica live candidate access appear test', 'ror record push interchange show error eps', 'text box accept texts skip next one empower test firefox', 'pdq certificate code generate eps entries area amendment file load', 'email server metrica day mail limit per mail box breach applications block send mail hours', 'candidates item mark report mei c accurately show mark candidate could award', 'fee late fee section disappear user click venues receive institution tabs session detail', 'provide functionality upload new versions bmat secure ebook', 'examiner push sts eps', 'unable export select candidates register candidates page system throw error upper record limit reach', 'unable export test form pdf html firefox', 'unable view edit data users ems', 'unit tittle grid change errorniously next page click magnify glass', 'user able enter card expiry date payment page', 'users get timeout error try use advance search filter rat', 'add comment item cp site non ascii character item content replace double escape html entities comment save', 'centre make move entry case entries treat entry r', 'eps esolcr push slower expect cause delay sor generation', 'create session test timer get disable', 'eps override third grade syllabus j j even judgemental', 'endorsement grade appear twice result file ocr endorse qualifications', 'error message beyond specific record set receive user try migrate data dmas drd', 'create equation editor convert create distort image print folder', 'examiners complete mark first time multiple mark ids see error message select responses complete exception list', 'log impersonate candidate register bmat appear phone number field miss check detail screen', 'update workflow task lock review instead go next stage go final media creation', 'user try bulk upload responses data use csv file metrica system take much time sometimes even time', 'problem data type conversion lead import edi file failure', 'qppd feed failure due incorrect ams trail space find libs database', 'use ipad iphone buy test metrica candidate shop user tick already account go add login detail page switch need make account screen', 'whenever user try access institutions tab admin access database crash say error occur', 'update workflow stage task item users get error', 'cams bulk buy process', 'zero mark report generate manually need add functionality application', 'new feature need interchange enable user amend claim', 'new feature need interchange enable user upload large file', 'new feature need modman enable user upload help supportive document website', 'new feature need interchange enable user download download file history', 'new feature need ukvi enable admin user delete applciation user', 'new feature need libs enable user download bank access report', 'new feature need eps enable user download report base user input', 'new feature need cie direct enable user copy old user message new user']\n"
     ]
    }
   ],
   "source": [
    "def preprocess(document, stem=False):\n",
    "    'changes document to lower case and removes stopwords'\n",
    "\n",
    "    # change sentence to lower case\n",
    "    document = document.lower()\n",
    "    document = re.sub(\"'\", \"\",document)\n",
    "    document = re.sub(\"(\\\\d|\\\\W)+\",\" \",document)\n",
    "\n",
    "    # tokenize into words\n",
    "    words = word_tokenize(document)\n",
    "\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # snowball stemmer\n",
    "    #stemmer = SnowballStemmer(\"english\")\n",
    "    #words = [stemmer.stem(token) for token in words]\n",
    "    \n",
    "    if stem:\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    else:\n",
    "        words = [wordnet_lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "\n",
    "    # join words to make sentence\n",
    "    document = \" \".join(words)\n",
    "    \n",
    "    return document\n",
    "\n",
    "documents = [preprocess(document) for document in documents]\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(documents).to_csv('debt_desc_stage2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normalization failure -  SAP system sends duplicate script to STS, resulting job failure at STS'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob((processed_data['Debt_Description'][1]))\n",
    "str(blob.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Normalization', 'NN'),\n",
       " ('failure', 'NN'),\n",
       " ('SAP', 'NNP'),\n",
       " ('sytem', 'NN'),\n",
       " ('sends', 'VBZ'),\n",
       " ('duplicate', 'JJ'),\n",
       " ('scripts', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('STS', 'NNP'),\n",
       " ('resulting', 'VBG'),\n",
       " ('job', 'NN'),\n",
       " ('failure', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('STS', 'NNP')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_txt(text):\n",
    "  return TextBlob(text).sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subj_txt(text):\n",
    "  return  TextBlob(text).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dattaa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "processed_data['polarity'] = processed_data['Debt_Description'].apply(polarity_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dattaa\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "processed_data['subjectivity'] = processed_data['Debt_Description'].apply(subj_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        return [{'pos':  row['polarity'], 'sub': row['subjectivity']} for _, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the text\n",
    "            ('Debt_Description', Pipeline([\n",
    "                ('selector', ItemSelector(key='Debt_Description')),\n",
    "                ('tfidf', TfidfVectorizer( min_df =3, max_df=0.2, max_features=None, \n",
    "                    strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                    ngram_range=(1, 10), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "                    stop_words = None, preprocessor=preprocess)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for pulling metadata features\n",
    "            ('stats', Pipeline([\n",
    "                ('selector', ItemSelector(key=['polarity', 'subjectivity'])),\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "        # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'Debt_Description': 0.9,\n",
    "            'stats': 1.5,\n",
    "        },\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 40\n",
    "X = processed_data[['Debt_Description', 'polarity', 'subjectivity']]\n",
    "y =processed_data['Debt_Class']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = list(zip(X,y))\n",
    "transformed_dataset = pd.DataFrame(list(zip(X,y)), columns=['Debt_Description', 'Debt_Class'])\n",
    "transformed_dataset.to_excel('data/Transformed_Data_TechDebt.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('union',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('Debt_Description',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  ItemSelector(key='Debt_Description')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=True,\n",
       "                                                                                  max_df=0.2,\n",
       "                                                                                  max_feat...\n",
       "                                                                                  use_idf=1,\n",
       "                                                                                  vocabulary=None))],\n",
       "                                                          verbose=False)),\n",
       "                                                ('stats',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('selector',\n",
       "                                                                  ItemSelector(key=['polarity',\n",
       "                                                                                    'subjectivity'])),\n",
       "                                                                 ('stats',\n",
       "                                                                  TextStats()),\n",
       "                                                                 ('vect',\n",
       "                                                                  DictVectorizer(dtype=<class 'numpy.float64'>,\n",
       "                                                                                 separator='=',\n",
       "                                                                                 sort=True,\n",
       "                                                                                 sparse=True))],\n",
       "                                                          verbose=False))],\n",
       "                              transformer_weights={'Debt_Description': 0.9,\n",
       "                                                   'stats': 1.5},\n",
       "                              verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the number of features in train and test correspond: (196, 215) - (50, 215)\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_vec = pipeline.transform(x_train)\n",
    "test_vec = pipeline.transform(x_test)\n",
    "print(\"Checking that the number of features in train and test correspond: %s - %s\" % (train_vec.shape, test_vec.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC & SGD Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sv = LinearSVC(C=1, class_weight='balanced', multi_class='ovr', random_state=40, max_iter=10000) #Support Vector machines\n",
    "clf_sgd = SGDClassifier(max_iter=200,) # Stochastic Gradient Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77272727 0.76923077 0.8       ]\n",
      "Mean score: 0.781 (+/-0.014)\n",
      "[0.74242424 0.78461538 0.76923077]\n",
      "Mean score: 0.765 (+/-0.017)\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clfs = [clf_sv, clf_sgd]\n",
    "cv = 3\n",
    "for clf in clfs:\n",
    "    scores = cross_val_score(clf,train_vec, y_train, cv=cv, scoring=\"accuracy\" )\n",
    "    print (scores)\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
    "        np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.81 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "clf_sv.fit(train_vec, y_train )\n",
    "y_pred = clf_sv.predict(test_vec)\n",
    "list_result =[]\n",
    "list_result.append((\"SVC\",accuracy_score(y_test, y_pred)))\n",
    "clf_sgd.fit(train_vec, y_train )\n",
    "y_pred = clf_sgd.predict(test_vec)\n",
    "list_result.append((\"SGD\",accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep Learning and Spacy Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --ignore-installed --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, LSTM, Embedding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Input, LSTM, Bidirectional, Activation, Conv1D, GRU, TimeDistributed\n",
    "from keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D, Add, Flatten, SpatialDropout1D\n",
    "from keras.layers import GlobalAveragePooling1D, BatchNormalization, concatenate\n",
    "from keras.layers import Reshape, merge, Concatenate, Lambda, Average\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "X = processed_data['Debt_Description']\n",
    "y = processed_data['Debt_Class']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "Y = np_utils.to_categorical(y)\n",
    "##Create the tf-idf vector\n",
    "vectorizer = TfidfVectorizer( min_df =3, max_df=0.2, max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = None, preprocessor=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.2, max_features=None,\n",
       "                min_df=3, ngram_range=(1, 1), norm='l2',\n",
       "                preprocessor=<function preprocess at 0x000000000EB0FF28>,\n",
       "                smooth_idf=1, stop_words=None, strip_accents='unicode',\n",
       "                sublinear_tf=1, token_pattern='\\\\w{1,}', tokenizer=None,\n",
       "                use_idf=1, vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 40\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=seed, stratify =y)\n",
    "vectorizer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 30, 117, 142]\n"
     ]
    }
   ],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\n",
    "tokenize = vectorizer.build_tokenizer()\n",
    "preprocess = vectorizer.build_preprocessor()\n",
    " \n",
    "def to_sequence(tokenizer, preprocessor, index, text):\n",
    "    words = tokenizer(preprocessor(text))\n",
    "    indexes = [index[word] for word in words if word in index]\n",
    "    return indexes\n",
    "\n",
    "X_train_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in x_train]\n",
    "print(X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165\n",
      " 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165\n",
      " 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165\n",
      " 165 165  95  30 117 142]\n"
     ]
    }
   ],
   "source": [
    "# Compute the max lenght of a text\n",
    "\n",
    "MAX_SEQ_LENGHT=60\n",
    "\n",
    "N_FEATURES = len(vectorizer.get_feature_names())\n",
    "X_train_sequences = pad_sequences(X_train_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)\n",
    "print(X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in x_test]\n",
    "X_test_sequences = pad_sequences(X_test_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS_LEN= 300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EMBEDDINGS_LEN = 300\n",
    "\n",
    "embeddings_index = np.zeros((len(vectorizer.get_feature_names()) + 1, EMBEDDINGS_LEN))\n",
    "for word, idx in word2idx.items():\n",
    "    try:\n",
    "        embedding = nlp.vocab[word].vector\n",
    "        embeddings_index[idx] = embedding\n",
    "    except:\n",
    "        pass\n",
    "      \n",
    "print(\"EMBEDDINGS_LEN=\", EMBEDDINGS_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 60, 300)           49800     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1204      \n",
      "=================================================================\n",
      "Total params: 772,204\n",
      "Trainable params: 722,404\n",
      "Non-trainable params: 49,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    EMBEDDINGS_LEN,  # Embedding size\n",
    "                    weights=[embeddings_index],\n",
    "                    input_length=MAX_SEQ_LENGHT,\n",
    "                    trainable=False))\n",
    "model.add(LSTM(300, dropout=0.2))\n",
    "model.add(Dense(len(set(y)), activation='softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 20 samples\n",
      "Epoch 1/5\n",
      "176/176 [==============================] - ETA: 11s - loss: 1.4104 - accuracy: 0.180 - ETA: 4s - loss: 1.2970 - accuracy: 0.410 - ETA: 1s - loss: 1.1947 - accuracy: 0.52 - 8s 44ms/step - loss: 1.1396 - accuracy: 0.5568 - val_loss: 1.1553 - val_accuracy: 0.6500\n",
      "Epoch 2/5\n",
      "176/176 [==============================] - ETA: 2s - loss: 0.7523 - accuracy: 0.80 - ETA: 1s - loss: 0.7931 - accuracy: 0.79 - ETA: 0s - loss: 0.7933 - accuracy: 0.78 - 3s 17ms/step - loss: 0.7498 - accuracy: 0.7841 - val_loss: 1.0533 - val_accuracy: 0.6500\n",
      "Epoch 3/5\n",
      "176/176 [==============================] - ETA: 1s - loss: 0.7762 - accuracy: 0.76 - ETA: 1s - loss: 0.6661 - accuracy: 0.79 - ETA: 0s - loss: 0.5882 - accuracy: 0.81 - 4s 20ms/step - loss: 0.6252 - accuracy: 0.8011 - val_loss: 0.8615 - val_accuracy: 0.7500\n",
      "Epoch 4/5\n",
      "176/176 [==============================] - ETA: 2s - loss: 0.5625 - accuracy: 0.88 - ETA: 1s - loss: 0.5194 - accuracy: 0.87 - ETA: 0s - loss: 0.5667 - accuracy: 0.86 - 4s 21ms/step - loss: 0.5726 - accuracy: 0.8466 - val_loss: 0.7752 - val_accuracy: 0.7000\n",
      "Epoch 5/5\n",
      "176/176 [==============================] - ETA: 2s - loss: 0.4439 - accuracy: 0.86 - ETA: 1s - loss: 0.4647 - accuracy: 0.85 - ETA: 0s - loss: 0.4935 - accuracy: 0.83 - 4s 22ms/step - loss: 0.4691 - accuracy: 0.8352 - val_loss: 0.7323 - val_accuracy: 0.7500\n",
      "50/50 [==============================] - ETA:  - 0s 7ms/step\n",
      "Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sequences, y_train, \n",
    "          epochs=5, batch_size=50, verbose=1, \n",
    "          validation_split=0.1)\n",
    " \n",
    "scores = model.evaluate(X_test_sequences, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])  #\n",
    "list_result.append((\"LSTM Simple\", scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Testing & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x215 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = pd.DataFrame(['Azure Monitoring Alert','Customer information/Request for few functional areas of ESM','ADIP in MSUP is using different subject groups'], columns=['Debt_Description'])\n",
    "X_new['polarity'] = X_new['Debt_Description'].apply(polarity_txt)\n",
    "X_new['subjectivity'] = X_new['Debt_Description'].apply(subj_txt)\n",
    "test_vec_new = pipeline.transform(X_new)\n",
    "test_vec_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_transform(x):    \n",
    "    cat_dict = {0:'Functional',1:'Knowledge',2:'Operational',3:'Technical'}   \n",
    "    if x in cat_dict.keys():\n",
    "        return cat_dict[x]\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 <class 'int'>\n",
      "dict_keys([0, 1, 2, 3])\n",
      "2 <class 'int'>\n",
      "dict_keys([0, 1, 2, 3])\n",
      "3 <class 'int'>\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Debt_Description</th>\n",
       "      <th>Debt_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azure Monitoring Alert</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer information/Request for few functiona...</td>\n",
       "      <td>Operational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADIP in MSUP is using different subject groups</td>\n",
       "      <td>Technical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Debt_Description   Debt_Class\n",
       "0                             Azure Monitoring Alert    Technical\n",
       "1  Customer information/Request for few functiona...  Operational\n",
       "2     ADIP in MSUP is using different subject groups    Technical"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf_sv.predict(test_vec_new)\n",
    "result = pd.DataFrame(list(zip(X_new['Debt_Description'],list(y_pred_test))), columns=['Debt_Description', 'Debt_Class'])\n",
    "result['Debt_Class'] = result['Debt_Class'].apply(category_transform)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM Simple</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  accuracy\n",
       "0          SVC      0.84\n",
       "1          SGD      0.80\n",
       "2  LSTM Simple      0.80"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list_result, columns=['model', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(documents)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(X.shape)\n",
    "# print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=42)\n",
    "# #Naive Bayes Classifier\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(X_train,y_train)\n",
    "# clf.score(X_test,y_test)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
